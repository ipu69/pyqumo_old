{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эксперимент №2: расчет характеристик тандемной сети с узлами  PH/PH/1/N по трём моментам с помощью имитационного моделирования и машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом эксперименте мы рассчитаем различные характеристики сетей с линейной топологией, в которой случайные величины интервалов поступления и времени обслуживания будут задавать фазовыми распределениями. \n",
    "\n",
    "Сначала мы рассчитаем характеристики на заданной сетке статистических параметров с помощью имитационного моделирования сети. Аппроксимацию функцию распределения будем проводить по трем моментов с помощью алгоритма [1]. Затем используем полученные результаты для обучения нейросетевых и других моделей ML, которые сможем использовать для очень быстрой оценки характеристик сетей. Например, такой подход полезен при нахождении решений задач оптимизации топологии, когда характеристики сетей с линейной топологией являются ограничениями в алгоритме ветвей и границ. \n",
    "\n",
    "\n",
    "[1] Mary A. Johnson & Michael R. Taaffe (1989) Matching moments to phase distributions: Mixtures of erlang distributions of common order, Communications in Statistics. Stochastic Models, 5:4, 711-743, DOI: 10.1080/15326348908807131\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "import time\n",
    "from typing import Tuple\n",
    "import random\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib import patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Подключаем локальные пакеты\n",
    "from pyqumo.random import Distribution, Exponential, HyperExponential, Erlang\n",
    "from pyqumo.cqumo.sim import simulate_tandem\n",
    "\n",
    "\n",
    "from pyqumo.fitting.johnson89 import fit_mern2\n",
    "from pyqumo.stats import get_cv, get_skewness, get_noncentral_m2, get_noncentral_m3\n",
    "from pyqumo.random import HyperErlang\n",
    "\n",
    "# Поключаем пакеты для ML\n",
    "import math\n",
    "from sklearn.metrics import r2_score, mean_squared_error, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import engine\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настраиваем matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 25})\n",
    "# matplotlib.rcParams.update({'font.weight': 'bold'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std(m1, m2):\n",
    "    return (m2 - m1**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим переменные окружения, которые будут использоваться в эксперименте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нужно ли пересчитывать все, или можно использовать результаты из файлов\n",
    "FORCE_SIMULATION = False\n",
    "# SIM_FILE_NAME = '01_tandem_simulation.csv'\n",
    "SIM_FILE_NAME = 'Tandem_network_with_ph_ph_1_n_distribution.csv'\n",
    "SIM_FILE_DIR = 'data'\n",
    "SIM_FILE_PATH = os.path.join(SIM_FILE_DIR, SIM_FILE_NAME)\n",
    "\n",
    "# Зададим число пакетов, передачу которых по сети мы будем моделировать.\n",
    "# Чем выше это число, тем точнее результаты, но на их получение нужно больше времени.\n",
    "NUM_PACKETS = 1_000_000\n",
    "\n",
    "# Цветовая схема для графиков\n",
    "CMAP_NAME = 'viridis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Id            0 non-null      object\n",
      " 1   ArrM1         0 non-null      object\n",
      " 2   ArrM2         0 non-null      object\n",
      " 3   ArrM3         0 non-null      object\n",
      " 4   ArrAvg        0 non-null      object\n",
      " 5   ArrStd        0 non-null      object\n",
      " 6   ArrCv         0 non-null      object\n",
      " 7   ArrSkewness   0 non-null      object\n",
      " 8   SrvM1         0 non-null      object\n",
      " 9   SrvM2         0 non-null      object\n",
      " 10  SrvM3         0 non-null      object\n",
      " 11  SrvAvg        0 non-null      object\n",
      " 12  SrvStd        0 non-null      object\n",
      " 13  SrvCv         0 non-null      object\n",
      " 14  SrvSkewness   0 non-null      object\n",
      " 15  Rho           0 non-null      object\n",
      " 16  NetSize       0 non-null      object\n",
      " 17  Capacity      0 non-null      object\n",
      " 18  NumPackets    0 non-null      object\n",
      " 19  DelayAvg      0 non-null      object\n",
      " 20  DelayStd      0 non-null      object\n",
      " 21  DeliveryProb  0 non-null      object\n",
      "dtypes: object(22)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "COLUMNS = (\n",
    "    'ArrM1',\n",
    "    'ArrM2',\n",
    "    'ArrM3',\n",
    "    'ArrAvg', \n",
    "    'ArrStd', \n",
    "    'ArrCv',\n",
    "    'ArrSkewness',\n",
    "    'SrvM1',\n",
    "    'SrvM2',\n",
    "    'SrvM3',\n",
    "    'SrvAvg', \n",
    "    'SrvStd', \n",
    "    'SrvCv',\n",
    "    'SrvSkewness', \n",
    "    'Rho', \n",
    "    'NetSize', \n",
    "    'Capacity', \n",
    "    'NumPackets',\n",
    "    'DelayAvg', \n",
    "    'DelayStd', \n",
    "    'DeliveryProb',\n",
    ")\n",
    "\n",
    "\n",
    "def save_sim_data(df: pd.DataFrame, ):\n",
    "    \"\"\"\n",
    "    Сохранить в файл данные о результатах имитационного моделирования.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(SIM_FILE_DIR):\n",
    "        os.makedirs(SIM_FILE_DIR)\n",
    "    df.to_csv(SIM_FILE_PATH, index_label='Id')\n",
    "\n",
    "    \n",
    "def load_sim_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Загрузить данные о резулдьтатах имитационного моделирования.\n",
    "    \"\"\"       \n",
    "    if os.path.exists(SIM_FILE_PATH):\n",
    "        return pd.read_csv(SIM_FILE_PATH)\n",
    "    return pd.DataFrame(columns=COLUMNS)\n",
    "\n",
    "sim_data = load_sim_data()\n",
    "sim_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(\n",
    "    df: pd.DataFrame, *,\n",
    "    arr_m1: float,\n",
    "    arr_m2: float,\n",
    "    arr_m3: float,\n",
    "    srv_m1: float,\n",
    "    srv_m2: float,\n",
    "    srv_m3: float,\n",
    "    net_size: int,\n",
    "    capacity: int,\n",
    "    num_packets: int,\n",
    "    force: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Выполнить симуляцию, если результатов нет в `df` или требуется их пересчитать, и вернуть новый `DataFrame`.\n",
    "    \"\"\"\n",
    "    row_df = df[\n",
    "        (df.ArrM1 == arr_m1) &\n",
    "        (df.ArrM2 == arr_m2) &\n",
    "        (df.ArrM3 == arr_m3) &\n",
    "        (df.ArrAvg == arr_m1) &\n",
    "        (df.ArrM2 == arr_m2) &\n",
    "        (df.ArrM3 == arr_m3) &\n",
    "        (df.SrvM1 == srv_m1) &\n",
    "        (df.SrvM2 == srv_m2) &\n",
    "        (df.SrvM3 == srv_m3) &\n",
    "        (df.NetSize == net_size) &\n",
    "        (df.Capacity == capacity)]\n",
    "    \n",
    "    # Вычислим признаки, которые говорят о необходимости пересчета:\n",
    "    no_row = len(row_df) == 0\n",
    "    not_enough_packets = (not no_row) and (row_df.NumPackets.iloc[0] < num_packets)\n",
    "\n",
    "    # Проверим, нужно ли пересчитать результаты:\n",
    "    if force or no_row or not_enough_packets:\n",
    "        arr,_  = fit_mern2(moments=[arr_m1, arr_m2, arr_m3])\n",
    "        srv,_ = fit_mern2(moments=[srv_m1, srv_m2, srv_m3])\n",
    "        ret = simulate_tandem([arr]* net_size, [srv] * net_size, capacity, num_packets)\n",
    "\n",
    "        row_data = {\n",
    "            'ArrM1': arr_m1,\n",
    "            'ArrM2': arr_m2,\n",
    "            'ArrM3': arr_m3,\n",
    "            'ArrAvg': arr_m1,\n",
    "            'ArrStd': get_std(arr_m1, arr_m2),\n",
    "            'ArrCv': get_cv(arr_m1, arr_m2),\n",
    "            'ArrSkewness': get_skewness(arr_m1, arr_m2, arr_m3),\n",
    "            'SrvM1': srv_m1,\n",
    "            'SrvM2': srv_m2,\n",
    "            'SrvM3': srv_m3,\n",
    "            'SrvAvg': srv_m1,\n",
    "            'SrvStd': get_std(srv_m1, srv_m2),\n",
    "            'SrvCv': get_cv(srv_m1, srv_m2),\n",
    "            'SrvSkewness': get_skewness(srv_m1, srv_m2, srv_m3),\n",
    "            'Rho': ret.get_utilization(net_size-1),\n",
    "            'NetSize': net_size,\n",
    "            'Capacity': capacity,\n",
    "            'NumPackets': num_packets,\n",
    "            'DelayAvg': ret.delivery_delays[0].avg,\n",
    "            'DelayStd': ret.delivery_delays[0].std,\n",
    "            'DeliveryProb': ret.delivery_prob[0],\n",
    "        }\n",
    "        # Если строки еще вообще не было, добавляем ее, а если была - обновляем:\n",
    "        if no_row:\n",
    "            df = df.append(row_data, ignore_index=True)\n",
    "        else:\n",
    "            df.update(pd.DataFrame(row_data, index=[row_df.index[0]]))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE_NUM = 100000\n",
    "# arr_m1 = np.zeros(SAMPLE_NUM)\n",
    "# arr_cv = np.zeros(SAMPLE_NUM)\n",
    "# arr_m2 = np.zeros(SAMPLE_NUM)\n",
    "# arr_skewness = np.zeros(SAMPLE_NUM)\n",
    "# arr_m3 = np.zeros(SAMPLE_NUM)\n",
    "\n",
    "# srv_m1 = np.zeros(SAMPLE_NUM)\n",
    "# srv_cv = np.zeros(SAMPLE_NUM)\n",
    "# srv_m2 = np.zeros(SAMPLE_NUM)\n",
    "# srv_skewness = np.zeros(SAMPLE_NUM)\n",
    "# srv_m3 = np.zeros(SAMPLE_NUM)\n",
    "\n",
    "# net_size = np.zeros(SAMPLE_NUM)\n",
    "# capacity = np.zeros(SAMPLE_NUM)\n",
    "\n",
    "# for i in range(SAMPLE_NUM):\n",
    "#     arr_m1[i] = np.random.uniform(0, 10)\n",
    "#     arr_cv[i] = np.random.uniform(0.5, 3)\n",
    "#     arr_m2[i] = get_noncentral_m2(arr_m1[i], arr_cv[i])\n",
    "#     arr_skewness[i] = np.random.uniform(arr_cv[i] - 1/arr_cv[i], 100)\n",
    "#     arr_m3[i] = get_noncentral_m3(arr_m1[i], arr_cv[i], arr_skewness[i])\n",
    "\n",
    "#     srv_m1[i] = np.random.uniform(0, 10)\n",
    "#     srv_cv[i] = np.random.uniform(0.5, 3)\n",
    "#     srv_m2[i] = get_noncentral_m2(srv_m1[i], srv_cv[i])\n",
    "#     srv_skewness[i] = np.random.uniform(srv_cv[i] - 1/srv_cv[i], 100)\n",
    "#     srv_m3[i] = get_noncentral_m3(srv_m1[i], srv_cv[i], srv_skewness[i])\n",
    "\n",
    "#     net_size[i] = np.random.randint(1, 20+1)\n",
    "#     capacity[i] = np.random.randint(6, 10+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if FORCE_SIMULATION:\n",
    "#     for i in tqdm(range(SAMPLE_NUM)):\n",
    "#         sim_data = simulate(\n",
    "#             sim_data,\n",
    "#             arr_m1=arr_m1[i],\n",
    "#             arr_m2=arr_m2[i],\n",
    "#             arr_m3=arr_m3[i],\n",
    "#             srv_m1=srv_m1[i],\n",
    "#             srv_m2=srv_m2[i],\n",
    "#             srv_m3=srv_m3[i],\n",
    "#             net_size=int(net_size[i]),\n",
    "#             capacity=int(capacity[i]),\n",
    "#             num_packets=NUM_PACKETS,\n",
    "#             force=FORCE_SIMULATION\n",
    "#         )\n",
    "\n",
    "#     print(sim_data.info())\n",
    "#     print(sim_data)\n",
    "\n",
    "#     # Сохраняем результат:\n",
    "#     save_sim_data(sim_data)\n",
    "# else:\n",
    "#     print(\"Going to use previously computed results. To re-run simulation, set FORCE_SIMULATION = True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_NUM = 5000\n",
    "arr_m1 = np.zeros(SAMPLE_NUM)\n",
    "arr_cv = np.zeros(SAMPLE_NUM)\n",
    "arr_m2 = np.zeros(SAMPLE_NUM)\n",
    "arr_skewness = np.zeros(SAMPLE_NUM)\n",
    "arr_m3 = np.zeros(SAMPLE_NUM)\n",
    "\n",
    "srv_m1 = np.zeros(SAMPLE_NUM)\n",
    "srv_cv = np.zeros(SAMPLE_NUM)\n",
    "srv_m2 = np.zeros(SAMPLE_NUM)\n",
    "srv_skewness = np.zeros(SAMPLE_NUM)\n",
    "srv_m3 = np.zeros(SAMPLE_NUM)\n",
    "\n",
    "net_size = np.zeros(SAMPLE_NUM)\n",
    "capacity = np.zeros(SAMPLE_NUM)\n",
    "\n",
    "for i in range(SAMPLE_NUM):\n",
    "    arr_m1[i] = np.random.uniform(10, 50)\n",
    "    arr_cv[i] = np.random.uniform(4.45, 8)\n",
    "    arr_m2[i] = get_noncentral_m2(arr_m1[i], arr_cv[i])\n",
    "    arr_skewness[i] = np.random.uniform(arr_cv[i] - 1/arr_cv[i], 150)\n",
    "    arr_m3[i] = get_noncentral_m3(arr_m1[i], arr_cv[i], arr_skewness[i])\n",
    "\n",
    "    srv_m1[i] = np.random.uniform(0.5, 1)\n",
    "    srv_cv[i] = np.random.uniform(4.45, 8)\n",
    "    srv_m2[i] = get_noncentral_m2(srv_m1[i], srv_cv[i])\n",
    "    srv_skewness[i] = np.random.uniform(srv_cv[i] - 1/srv_cv[i], 150)\n",
    "    srv_m3[i] = get_noncentral_m3(srv_m1[i], srv_cv[i], srv_skewness[i])\n",
    "\n",
    "    net_size[i] = np.random.randint(1, 20+1)\n",
    "    capacity[i] = np.random.randint(6, 10+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57809678e61b4bf7979bcb4e52955e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Id            0 non-null      float64\n",
      " 1   ArrM1         5000 non-null   float64\n",
      " 2   ArrM2         5000 non-null   float64\n",
      " 3   ArrM3         5000 non-null   float64\n",
      " 4   ArrAvg        5000 non-null   float64\n",
      " 5   ArrStd        5000 non-null   float64\n",
      " 6   ArrCv         5000 non-null   float64\n",
      " 7   ArrSkewness   5000 non-null   float64\n",
      " 8   SrvM1         5000 non-null   float64\n",
      " 9   SrvM2         5000 non-null   float64\n",
      " 10  SrvM3         5000 non-null   float64\n",
      " 11  SrvAvg        5000 non-null   float64\n",
      " 12  SrvStd        5000 non-null   float64\n",
      " 13  SrvCv         5000 non-null   float64\n",
      " 14  SrvSkewness   5000 non-null   float64\n",
      " 15  Rho           5000 non-null   float64\n",
      " 16  NetSize       5000 non-null   float64\n",
      " 17  Capacity      5000 non-null   float64\n",
      " 18  NumPackets    5000 non-null   float64\n",
      " 19  DelayAvg      5000 non-null   float64\n",
      " 20  DelayStd      5000 non-null   float64\n",
      " 21  DeliveryProb  5000 non-null   float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 859.5 KB\n",
      "None\n",
      "      Id      ArrM1          ArrM2         ArrM3     ArrAvg      ArrStd  \\\n",
      "0    NaN  10.215354    5776.177657  2.916002e+07  10.215354   75.311514   \n",
      "1    NaN  36.734177   84495.283797  1.589300e+09  36.734177  288.350280   \n",
      "2    NaN  40.932609   72744.262426  1.943913e+09  40.932609  266.587291   \n",
      "3    NaN  24.237312   25889.667155  1.520365e+08  24.237312  159.066715   \n",
      "4    NaN  39.024067   50698.305890  7.628267e+08  39.024067  221.755334   \n",
      "...   ..        ...            ...           ...        ...         ...   \n",
      "4995 NaN  17.784788   11748.036944  5.667260e+07  17.784788  106.919307   \n",
      "4996 NaN  35.571314   27418.343634  9.899126e+07  35.571314  161.718970   \n",
      "4997 NaN  25.695240   20968.266938  2.429963e+08  25.695240  142.506216   \n",
      "4998 NaN  29.230321   31644.634886  3.163075e+08  29.230321  175.471431   \n",
      "4999 NaN  45.028923  103776.651996  3.035687e+09  45.028923  318.981266   \n",
      "\n",
      "         ArrCv  ArrSkewness     SrvM1      SrvM2  ...    SrvStd     SrvCv  \\\n",
      "0     7.372384    67.856454  0.981282  55.802014  ...  7.405343  7.546602   \n",
      "1     7.849646    65.905260  0.947204  22.901394  ...  4.690863  4.952329   \n",
      "2     6.512834   102.138403  0.562496   9.889961  ...  3.094117  5.500694   \n",
      "3     6.562886    37.314821  0.908757  48.881987  ...  6.932254  7.628285   \n",
      "4     5.682527    69.419186  0.758724  26.445837  ...  5.086273  6.703723   \n",
      "...        ...          ...       ...        ...  ...       ...       ...   \n",
      "4995  6.011841    45.862924  0.605420  11.369255  ...  3.317035  5.478900   \n",
      "4996  4.546331    22.734772  0.580572  10.981776  ...  3.262624  5.619672   \n",
      "4997  5.546016    83.418207  0.989100  24.392175  ...  4.838787  4.892108   \n",
      "4998  6.003062    58.040692  0.928995  31.883498  ...  5.569602  5.995296   \n",
      "4999  7.083920    93.105954  0.966973  31.577902  ...  5.535600  5.724669   \n",
      "\n",
      "      SrvSkewness       Rho  NetSize  Capacity  NumPackets    DelayAvg  \\\n",
      "0       36.291182  0.439986     20.0      10.0   1000000.0  748.848514   \n",
      "1      121.762758  0.337884     15.0       6.0   1000000.0   37.321305   \n",
      "2       79.248921  0.142309     11.0      10.0   1000000.0   27.537158   \n",
      "3       61.947012  0.364477     15.0      10.0   1000000.0   90.851891   \n",
      "4       58.626350  0.244868     17.0       7.0   1000000.0   62.651336   \n",
      "...           ...       ...      ...       ...         ...         ...   \n",
      "4995   143.739132  0.456986     17.0       9.0   1000000.0   34.634430   \n",
      "4996   117.740412  0.173600     11.0       6.0   1000000.0   13.780545   \n",
      "4997   111.919192  0.548599     20.0      10.0   1000000.0   83.435069   \n",
      "4998    59.811208  0.290867     11.0       6.0   1000000.0   41.277204   \n",
      "4999   129.883562  0.256355     13.0       9.0   1000000.0   35.726487   \n",
      "\n",
      "         DelayStd  DeliveryProb  \n",
      "0     1646.696455      0.016898  \n",
      "1      223.737576      0.796696  \n",
      "2      191.173349      0.898970  \n",
      "3      567.806752      0.477602  \n",
      "4      349.045559      0.583091  \n",
      "...           ...           ...  \n",
      "4995   215.589112      0.673070  \n",
      "4996   136.194230      0.936912  \n",
      "4997   314.144294      0.517034  \n",
      "4998   234.298841      0.683283  \n",
      "4999   287.342430      0.825022  \n",
      "\n",
      "[5000 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "FORCE_SIMULATION_V2 = True\n",
    "if FORCE_SIMULATION_V2:\n",
    "    for i in tqdm(range(SAMPLE_NUM)):\n",
    "        sim_data = simulate(\n",
    "            sim_data,\n",
    "            arr_m1=arr_m1[i],\n",
    "            arr_m2=arr_m2[i],\n",
    "            arr_m3=arr_m3[i],\n",
    "            srv_m1=srv_m1[i],\n",
    "            srv_m2=srv_m2[i],\n",
    "            srv_m3=srv_m3[i],\n",
    "            net_size=int(net_size[i]),\n",
    "            capacity=int(capacity[i]),\n",
    "            num_packets=NUM_PACKETS,\n",
    "            force=FORCE_SIMULATION\n",
    "        )\n",
    "\n",
    "    print(sim_data.info())\n",
    "    print(sim_data)\n",
    "\n",
    "    # Сохраняем результат:\n",
    "    save_sim_data(sim_data)\n",
    "else:\n",
    "    print(\"Going to use previously computed results. To re-run simulation, set FORCE_SIMULATION = True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПОСТРОЕНИЕ ПРОГНОЗНОЙ МОДЕЛЕЙ С ПОМОЩЬЮ МЕТОДОВ МАШИННОГО ОБУЧЕНИЯ\n",
    "\n",
    "При расчете многофазных сетей массового обслуживания, мы часто прибегаем к методу имитационного моделирования из-за отсутствия аналитеческих методов расчета. В нашей работе мы использовали модель с фазовыми типами распреления случайных величин для интревалов поступления и времени обслуживания.\n",
    "\n",
    "Мы получили данные имитационного моделирования `sim_data` объемом 101424 строк.\n",
    " \n",
    "`Tandem_network_with_ph_distribution.csv`\n",
    "\n",
    "На выходе рассчитывались время межконцевой задержки и вероятность доставки пакетов. К сожалению расчет характеристик производительности сети с помощью имитационного моделирования имеет один существенный минус - это большие затраты по времени. Этот минус оказывает ощутимое влияние в итеративных задач. Например, при проектировании беспроводной сети связи на стадии выбора топологии будущей сети, когда на каждом новом шаге итерации необходимо производить оценку характеристик.\n",
    "\n",
    "Решением этой проблемы является использования моделей МО для оценки необходимых характеристик беспроводной сети связи.\n",
    "\n",
    "В качестве **предикторов** моделей будем использовать следующие величины:\n",
    "\n",
    "- **ArrM1** - Первый момент распределения случайного времени между поступлениями пакетов;\n",
    "- **ArrM2** - Второй момент распределения случайного времени между поступлениями пакетов;\n",
    "- **ArrM3** - Третий момент распределения случайного времени между поступлениями пакетов;\n",
    "- **SrvM1** - Первый момент распределения случайного времени обслуживания;\n",
    "- **SrvM2** - Второй момент распределения случайного времени обслуживания;\n",
    "- **SrvM3** - Третий момент распределения случайного времени обслуживания;\n",
    "- **Capacity** - Размер буфера очередей на фазах;\n",
    "- **NetSize** - Количество станций в многофазной сети.\n",
    "\n",
    "Проноз будем строить для выходных данных моделирования - времени межконцевой задержки и вероятности доставки пакетов.\n",
    "\n",
    "**Цель:** по полученным данным построить **прогнозные модели** для времени межконцевой задержки и вероятности доставки пакетов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПОСТРОЕНИЕ ПРОГНОЗНОЙ МОДЕЛИ ВРЕМЕНИ МЕЖКОНЦЕВОЙ ЗАДЕРЖКИ МНОГОФАЗНОЙ СЕТИ МАСОВОГО ОБСЛУЖИВАНИЯ С ЛИНЕЙНОЙ ТОПОЛОГИЕЙ\n",
    "\n",
    "Для оценки времени задержек построим _регрессионную модель_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ТАБЛИЦА ТРЕНИРОЧНЫХ ДАННЫХ\n",
    "Мы получили данные симуляции для различных входных параметров. В общей сложности объем выборки составил 101424 строк. Данную выборку будем использовать для обучения будущих моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "data = pd.read_csv('data/Tandem_network_with_ph_distribution.csv', index_col='Id')\n",
    "COLUMNS = [\n",
    "    'ArrM1',\n",
    "    'ArrM2',\n",
    "    'ArrM3',\n",
    "    'SrvM1',\n",
    "    'SrvM2',\n",
    "    'SrvM3',\n",
    "    'NetSize', \n",
    "    'Capacity',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных\n",
    "\n",
    "В полученных данных мы случайным образом генерировали величины времени поступления пакетов и времени обслуживания пакетов, задавая моменты $(\\mu_1, \\mu_2, \\mu_3) $  распределения случайным образом. Очевидно, мы сгенерируем данные при очень больших коэффициентах загрузках.\n",
    "\n",
    "Давайте взглянем на сгенерированные коэффициенты загрузок. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Utilization server ' r'$\\rho$' '\\n of generated data',fontweight=\"bold\")\n",
    "plt.plot(data['Rho'], 'or')\n",
    "plt.xlabel(r'Samples', fontweight=\"bold\");\n",
    "plt.ylabel(r'$\\rho$');\n",
    "plt.xticks(color='w')\n",
    "plt.grid()\n",
    "plt.savefig('data/images/samples_rho.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из графиков мы имеем значения $\\rho$ сильно превышающие диапазон $(0, 1)$. Нецелесообразно использовать такие данные для дальнейшего обучения моделей. Перед тем как начать отсекать строки, вспомни, что узлы нашей многофазной очереди имеют конечный буфер и пакеты при загруженном узле могут теряться. Значит загрузка на первом узле может быть $\\rho >> 1$. Поэтому ограничемся  диапазоном $\\rho \\in (0, 10]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data = data[data['Rho'] <= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приступим к тренировке моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, y_train, y_test = train_test_split(\n",
    "    simulation_data, simulation_data.loc[:, ['DelayAvg', 'DeliveryProb']], \n",
    "    test_size=0.33, \n",
    "    random_state=42)\n",
    "x_train = train_data.loc[:, COLUMNS]\n",
    "x_test = test_data.loc[:, COLUMNS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### МЕТРИКИ\n",
    "Для оценки полученных моделей нам будут необходимы метрики, а именно:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Стандартное отклонение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Standard deviation between simulation model \n",
    "    values and estimates\n",
    "    \"\"\"\n",
    "    return math.sqrt(np.sum((x-y)**2) / (len(x) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Коэффициент корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Correlation coefficient between simulation model \n",
    "    values and estimate \n",
    "    \"\"\"\n",
    "    r = np.corrcoef(x, y)\n",
    "    return r[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- среднеквадратичная ошибка;\n",
    "\n",
    "```sklearn.metrics.mean_squared_error ```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- и коэффициент детерминации.\n",
    "\n",
    "```sklearn.metrics.r2_score```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приступим непосредственно к обучению\n",
    "\n",
    "-  ## Задача регресии МНК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prepare regression model using Least Squares algorithm\"\"\"\n",
    "def get_ls_regression_model(x_train, x_test, \n",
    "                            y_train, y_test) -> (np.ndarray, LinearRegression):\n",
    "    ls = LinearRegression()\n",
    "    # ls = Ridge(alpha=.5)\n",
    "    ls.fit(x_train, y_train)\n",
    "    ls_y = ls.predict(x_test)\n",
    "\n",
    "    return ls_y, ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_delay_estimate, ls = get_ls_regression_model(x_train, x_test, \n",
    "                                                y_train['DelayAvg'], \n",
    "                                                y_test['DelayAvg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R = {corr(y_test[\"DelayAvg\"], ls_delay_estimate):.3f}')\n",
    "print(f'STD = {std(y_test[\"DelayAvg\"], ls_delay_estimate):.3f}')\n",
    "print(f'MSE = {mean_squared_error(y_test[\"DelayAvg\"], ls_delay_estimate):.3f}')\n",
    "print(f'R2 = {r2_score(y_test[\"DelayAvg\"], ls_delay_estimate):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame для отриосвки графиков\n",
    "draw_data = test_data\n",
    "draw_data.loc[:,'DelayAvgTest'] = y_test.loc[:,'DelayAvg']\n",
    "draw_data.loc[:, 'LsDelayEst'] = ls_delay_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# plt.grid()\n",
    "# cm = plt.get_cmap('Greens')\n",
    "# col = [cm(float(i)/(len(y_test))) for i in range((len(y_test)))]\n",
    "# ax.scatter(draw_data['LsDelayEst'], draw_data['DelayAvgTest'], c=col)\n",
    "# x = np.linspace(0,800,1000)\n",
    "# ax.plot(x, x, linestyle='-', linewidth=2.4, color='aquamarine')\n",
    "# ax.set_title('Least Squares model \\n SCATTER DIAGRAM \\n  e2e delay estimate', fontweight='bold')\n",
    "\n",
    "# plt.xlim([0, 800])\n",
    "# plt.ylim([0, 800])\n",
    "\n",
    "# plt.xlabel(r'$Test \\ Samples$');\n",
    "# plt.ylabel(r'$Least \\ Squares \\ Estimates$');\n",
    "# plt.savefig('data/images/ls_scatter_diagram.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_size = draw_data['NetSize'].unique()\n",
    "# net_size.sort()\n",
    "# fig = plt.figure(figsize=(30, 35))\n",
    "# fig.suptitle('Least Squares \\n End2end delay estimates \\n',fontweight=\"bold\", fontsize=25)\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "\n",
    "# for i in net_size:\n",
    "#     draw_hist = draw_data.loc[draw_data['NetSize']==i]\n",
    "#     ax = fig.add_subplot(5, 4, int(i))\n",
    "#     ax.title.set_text('Network size is ' + str(int(i)))\n",
    "#     ax = sns.histplot(draw_hist.loc[:,'LsDelayEst'], \n",
    "#                       color=\"mediumseagreen\", \n",
    "#                       label=\"Least squares model\", kde=True)\n",
    "#     ax = sns.histplot(draw_hist.loc[:,'DelayAvgTest'], \n",
    "#                       color=\"orangered\", \n",
    "#                       label=\"Delay test\", kde=True)\n",
    "#     plt.legend()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_size = draw_data['NetSize'].unique()\n",
    "net_size.sort()\n",
    "fig = plt.figure(figsize=(20, 21))\n",
    "fig.suptitle('Least Squares \\n End2end delay estimates \\n', \n",
    "             fontsize=40,\n",
    "             fontweight='bold')\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "k = 1\n",
    "for i in net_size:\n",
    "    size = [1, 5, 10, 20]\n",
    "   \n",
    "    if i in size:\n",
    "        draw_hist = draw_data.loc[draw_data['NetSize']==i]\n",
    "        ax = fig.add_subplot(2, 2, k)\n",
    "        plt.title('Network size is ' + str(int(i)), fontweight='bold')\n",
    "        ax = sns.histplot(draw_hist.loc[:,'LsDelayEst'], \n",
    "                          color=\"mediumseagreen\", \n",
    "                          label=\"Least squares model\", kde=True)\n",
    "        ax = sns.histplot(draw_hist.loc[:,'DelayAvgTest'], \n",
    "                          color=\"orangered\", \n",
    "                          label=\"Delay test\", kde=True)\n",
    "        \n",
    "        k += 1\n",
    "        plt.xlabel('Delays')\n",
    "plt.legend()\n",
    "plt.savefig('data/images/ls_histogram.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ## Задача регресии на дереве решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prepare regression model using Decision Tree algorithm\"\"\"\n",
    "def get_tree_regression_model(x_train, x_test, \n",
    "                              y_train, y_test, \n",
    "                              max_depth=36, \n",
    "                              splitter='best') -> (np.ndarray, DecisionTreeRegressor):\n",
    "    tree_reg = DecisionTreeRegressor(max_depth=max_depth, splitter=splitter)\n",
    "    tree_reg.fit(x_train, y_train)\n",
    "    tree_y = tree_reg.predict(x_test)\n",
    "    \n",
    "    # print(f'R = {corr(y_test, tree_y):.3f}')\n",
    "    # print(f'STD = {std(y_test, tree_y):.3f}')\n",
    "    # print(f'MSE = {mean_squared_error(y_test, tree_y):.3f}')\n",
    "\n",
    "    return tree_y, tree_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_delay_estimate, tree_reg = get_tree_regression_model(x_train, x_test, \n",
    "                                                        y_train['DelayAvg'], \n",
    "                                                        y_test['DelayAvg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R = {corr(y_test[\"DelayAvg\"], tree_delay_estimate,):.3f}')\n",
    "print(f'STD = {std(y_test[\"DelayAvg\"], tree_delay_estimate,):.3f}')\n",
    "print(f'MSE = {mean_squared_error(y_test[\"DelayAvg\"], tree_delay_estimate,):.3f}')\n",
    "print(f'R2 = {r2_score(y_test[\"DelayAvg\"], tree_delay_estimate,):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data.loc[:, 'TreeDelayEst'] = tree_delay_estimate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунке представлена **диаграмма рассеивания**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# # plt.subplots_adjust(top=0.5)\n",
    "# plt.grid()\n",
    "# cm = plt.get_cmap('autumn')\n",
    "# col = [cm(float(i)/(len(y_test))) for i in range((len(y_test)))]\n",
    "# ax.scatter(draw_data['TreeDelayEst'], draw_data['DelayAvgTest'], c=col)\n",
    "# x = np.linspace(0,800,1000)\n",
    "# ax.plot(x, x, linestyle='-', linewidth=2.4, color='red')\n",
    "# ax.set_title('Tree model \\n SCATTER DIAGRAM \\n  e2e delay estimate', fontweight='bold')\n",
    "\n",
    "# plt.xlim([0, 800])\n",
    "# plt.ylim([0, 800])\n",
    "\n",
    "# plt.xlabel(r'$Test \\ Samples$');\n",
    "# plt.ylabel(r'$Tree \\ estimates$');\n",
    "# plt.savefig('data/images/tree_scatter_diagram.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Для различных длин тандема сетей представлены гистограммы оценок времени межконцевых задержек тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_size = draw_data['NetSize'].unique()\n",
    "# net_size.sort()\n",
    "# fig = plt.figure(figsize=(22, 35))\n",
    "# fig.suptitle('Tree decision \\n End2end delay estimates \\n', fontsize=16)\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "\n",
    "# for i in net_size:\n",
    "#     draw_hist = draw_data.loc[draw_data['NetSize']==i]\n",
    "#     ax = fig.add_subplot(5, 4, int(i))\n",
    "#     ax.title.set_text('Network size is ' + str(int(i)))\n",
    "#     ax = sns.histplot(draw_hist.loc[:,'TreeDelayEst'], \n",
    "#                       color=\"gold\", \n",
    "#                       label=\"Tree model\", kde=True)\n",
    "#     ax = sns.histplot(draw_hist.loc[:,'DelayAvgTest'], \n",
    "#                       color=\"orangered\", \n",
    "#                       label=\"Delay test\", kde=True)\n",
    "#     plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_size = draw_data['NetSize'].unique()\n",
    "net_size.sort()\n",
    "fig = plt.figure(figsize=(20, 21))\n",
    "fig.suptitle('Decision Tree \\n End2end delay estimates \\n', \n",
    "             fontsize=40,\n",
    "             fontweight='bold')\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "k = 1\n",
    "for i in net_size:\n",
    "    size = [1, 5, 10, 20]\n",
    "   \n",
    "    if i in size:\n",
    "        draw_hist = draw_data.loc[draw_data['NetSize']==i]\n",
    "        ax = fig.add_subplot(2, 2, k)\n",
    "        plt.title('Network size is ' + str(int(i)), fontweight='bold')\n",
    "        ax = sns.histplot(draw_hist.loc[:,'TreeDelayEst'], \n",
    "                          color=\"gold\", \n",
    "                          label=\"Tree model\", kde=True)\n",
    "        ax = sns.histplot(draw_hist.loc[:,'DelayAvgTest'], \n",
    "                          color=\"orangered\", \n",
    "                          label=\"Delay test\", kde=True)\n",
    "        \n",
    "        k += 1\n",
    "        plt.xlabel('Delays')\n",
    "plt.legend()\n",
    "plt.savefig('data/images/tree_histogram.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ## Задача регрессии с помощью градиентного бустинга на деревьях решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prepare regression model using Gradient Boosting algorithm\"\"\"\n",
    "def get_gtb_regression_model(x_train, x_test, \n",
    "                             y_train, y_test, \n",
    "                             n_estimators=100, \n",
    "                             learning_rate=.1,\n",
    "                             max_depth=10) -> (np.ndarray, GradientBoostingRegressor):\n",
    "    gtb = GradientBoostingRegressor(n_estimators=n_estimators, \n",
    "                                    learning_rate=learning_rate, \n",
    "                                    max_depth=max_depth)\n",
    "    gtb.fit(x_train, y_train)\n",
    "    gtb_y = gtb.predict(x_test)\n",
    "\n",
    "    return gtb_y, gtb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtb_delay_estimate, gtb = get_tree_regression_model(x_train, x_test, \n",
    "                                               y_train['DelayAvg'], \n",
    "                                               y_test['DelayAvg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R = {corr(y_test[\"DelayAvg\"], gtb_delay_estimate,):.3f}')\n",
    "print(f'STD = {std(y_test[\"DelayAvg\"], gtb_delay_estimate,):.3f}')\n",
    "print(f'MSE = {mean_squared_error(y_test[\"DelayAvg\"], gtb_delay_estimate,):.3f}')\n",
    "print(f'R2 = {r2_score(y_test[\"DelayAvg\"], gtb_delay_estimate,):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data.loc[:, 'GTBDelayEst'] = gtb_delay_estimate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# plt.grid()\n",
    "# cm = plt.get_cmap('Blues')\n",
    "# col = [cm(float(i)/(len(y_test))) for i in range((len(y_test)))]\n",
    "# ax.scatter(draw_data['TreeDelayEst'], draw_data['DelayAvgTest'], c=col)\n",
    "# x = np.linspace(0,800,1000)\n",
    "# ax.plot(x, x, linestyle='-', linewidth=2.4, color='dodgerblue')\n",
    "# ax.set_title('Gradient Tree Boosting model \\n SCATTER DIAGRAM \\n  e2e delay estimate', fontweight='bold')\n",
    "\n",
    "# plt.xlim([0, 800])\n",
    "# plt.ylim([0, 800])\n",
    "\n",
    "# plt.xlabel(r'$Test \\ Samples$');\n",
    "# plt.ylabel(r'$GTB \\ estimates$');\n",
    "# plt.savefig('data/images/gtb_scatter_diagram.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Для различных длин тандема сетей представлены гистограммы оценок времени межконцевых задержек тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_size = draw_data['NetSize'].unique()\n",
    "# net_size.sort()\n",
    "# fig = plt.figure(figsize=(22, 35))\n",
    "# fig.suptitle('Gradient Tree Boosting \\n End2end delay estimates \\n', fontsize=16)\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "\n",
    "# for i in net_size:\n",
    "#     draw_hist = draw_data.loc[draw_data['NetSize']==i]\n",
    "#     ax = fig.add_subplot(5, 4, int(i))\n",
    "#     ax.title.set_text('Network size is ' + str(int(i)))\n",
    "#     ax = sns.histplot(draw_hist.loc[:,'GTBDelayEst'], \n",
    "#                       color=\"mediumblue\", \n",
    "#                       label=\"Gradient Boosting model\", kde=True)\n",
    "#     ax = sns.histplot(draw_hist.loc[:,'DelayAvgTest'], \n",
    "#                       color=\"orangered\", \n",
    "#                       label=\"Delay test\", kde=True)\n",
    "#     plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_size = draw_data['NetSize'].unique()\n",
    "# net_size.sort()\n",
    "# fig = plt.figure(figsize=(20, 28))\n",
    "# fig.suptitle('Least Squares \\n End2end delay estimates \\n', \n",
    "#              fontsize=30,\n",
    "#              fontweight='bold')\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "# k = 1\n",
    "# for i in net_size:\n",
    "#     size = [1, 5, 10, 20]\n",
    "   \n",
    "#     if i in size:\n",
    "#         draw_hist = draw_data.loc[draw_data['NetSize']==i]\n",
    "#         ax = fig.add_subplot(3, 2, k)\n",
    "#         plt.title('Network size is ' + str(int(i)), fontweight='bold')\n",
    "#         ax = sns.histplot(draw_hist.loc[:,'LsDelayEst'], \n",
    "#                           color=\"mediumseagreen\", \n",
    "#                           label=\"Least squares model\", kde=True)\n",
    "#         ax = sns.histplot(draw_hist.loc[:,'DelayAvgTest'], \n",
    "#                           color=\"orangered\", \n",
    "#                           label=\"Delay test\", kde=True)\n",
    "        \n",
    "#         k += 1\n",
    "#         plt.xlabel('Delays')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_size = draw_data['NetSize'].unique()\n",
    "net_size.sort()\n",
    "fig = plt.figure(figsize=(20, 21))\n",
    "fig.suptitle('Gradient Tree Boosting \\n End2end delay estimates \\n', \n",
    "             fontsize=40,\n",
    "             fontweight='bold')\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "k = 1\n",
    "for i in net_size:\n",
    "    size = [1, 5, 10, 20]\n",
    "   \n",
    "    if i in size:\n",
    "        draw_hist = draw_data.loc[draw_data['NetSize']==i]\n",
    "        ax = fig.add_subplot(2, 2, k)\n",
    "        plt.title('Network size is ' + str(int(i)), fontweight='bold')\n",
    "        ax = sns.histplot(draw_hist.loc[:,'TreeDelayEst'], \n",
    "                          color=\"mediumblue\", \n",
    "                          label=\"Gradient Boosting model\", kde=True)\n",
    "        ax = sns.histplot(draw_hist.loc[:,'DelayAvgTest'], \n",
    "                          color=\"orangered\", \n",
    "                          label=\"Delay test\", kde=True)\n",
    "        \n",
    "        \n",
    "        k += 1\n",
    "        plt.xlabel('Delays')\n",
    "plt.legend()\n",
    "plt.savefig('data/images/gtb_histogram.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ## Задача регрессии с помощью искуственной нейронной сети на алгоритме Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(table, stat) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"Prepare data for ANN\"\"\"\n",
    "    return (table - stat.loc['mean',:].transpose()) / stat.loc['std',:].transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо провести нормализацию входных данных перед тем, как непосредственно приступить к обучению нейронной сети "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normalize = normalize(x_train, simulation_data.loc[:,COLUMNS].describe())\n",
    "train_normalize.to_numpy();\n",
    "test_normalize = normalize(x_test, simulation_data.loc[:,COLUMNS].describe())\n",
    "test_normalize.to_numpy();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построем модель будущей сети. Наша сеть состоит из одного скрытого слоя. Для обучения будем использовать алгоритм Адама."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(size, activation='sigmoid') -> np.ndarray:\n",
    "    model = keras.Sequential([\n",
    "        # Input Layer\n",
    "#         layers.Dense(18, activation=activation, \n",
    "#                      use_bias=True, input_shape=[size]),\n",
    "        layers.Flatten(input_shape=[size]),\n",
    "        # Hidden Layer\n",
    "        layers.Dense(40, activation=activation, use_bias=True),\n",
    "        # Output layer\n",
    "        layers.Dense(1)])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mse'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_ann_regression_model(train_normalize, \n",
    "                             test_normalize, \n",
    "                             y_train_ann, y_test_ann, \n",
    "                             size,\n",
    "                             epochs=1000,\n",
    "                             activation='sigmoid') -> Tuple[np.ndarray, \n",
    "                                                            engine.sequential.Sequential]:\n",
    "    \n",
    "    ann = build_model(size=size)\n",
    "   \n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    EPOCHS = epochs\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    ann.fit(train_normalize, y_train_ann, epochs=EPOCHS, validation_split=0.3, verbose=0, \n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)])\n",
    "\n",
    "    ann_y = ann.predict(test_normalize).flatten();\n",
    "    \n",
    "    return ann_y, ann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ann_delay_estimate, ann = get_ann_regression_model(train_normalize, test_normalize,\n",
    "                                                   y_train['DelayAvg'], y_test['DelayAvg'],\n",
    "                                                   size=len(simulation_data.loc[:,COLUMNS].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R = {corr(y_test[\"DelayAvg\"], ann_delay_estimate):.3f}')\n",
    "print(f'STD = {std(y_test[\"DelayAvg\"], ann_delay_estimate):.3f}')\n",
    "print(f'MSE = {mean_squared_error(y_test[\"DelayAvg\"], ann_delay_estimate):.3f}')\n",
    "print(f'R2 = {r2_score(y_test[\"DelayAvg\"], ann_delay_estimate):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунке представлена диаграмма рассеивания полученной модели с помощью нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим в draw_data оценку ann_y \n",
    "draw_data['AnnDelayEst'] = ann_delay_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(figsize=(6, 6))\n",
    "# cm = plt.get_cmap('PuRd')\n",
    "# col = [cm(float(i)/(len(ann_delay_estimate))) for i in range((len(ann_delay_estimate)))]\n",
    "# ax = plt.scatter(draw_data['AnnDelayEst'], \n",
    "#                  draw_data['DelayAvgTest'], \n",
    "#                  c=col)\n",
    "# plt.subplots_adjust(top=0.95)\n",
    "# x = np.linspace(0,800,1000)\n",
    "# plt.plot(x, x, \n",
    "#          linestyle='-', \n",
    "#          linewidth=2.4, \n",
    "#          color='pink')\n",
    "# plt.title('ANN model \\n SCATTER DIAGRAM \\n  e2e delay estimate', fontweight='bold')\n",
    "\n",
    "# plt.xticks(color='w')\n",
    "# plt.yticks(color='w')\n",
    "\n",
    "# plt.xlim([0, 800])\n",
    "# plt.ylim([0, 800])\n",
    "\n",
    "# plt.xlabel(r'$Test \\ Samples$')\n",
    "# plt.ylabel(r'$ANN \\ estimates$')\n",
    "\n",
    "# plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_size = draw_data['NetSize'].unique()\n",
    "# net_size.sort()\n",
    "# fig = plt.figure(figsize=(22, 35))\n",
    "# fig.suptitle('Neural Network \\n End2end delay estimates \\n', fontsize=16)\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "\n",
    "# for i in net_size:\n",
    "#     draw_hist = draw_data.loc[draw_data['NetSize']==i]\n",
    "#     ax = fig.add_subplot(5, 4, int(i))\n",
    "#     ax.title.set_text('Network size is ' + str(int(i)))\n",
    "#     ax = sns.histplot(draw_hist.loc[:,'GTBDelayEst'], \n",
    "#                       color=\"fuchsia\", \n",
    "#                       label=\"Neural Networ model\", kde=True)\n",
    "#     ax = sns.histplot(draw_hist.loc[:,'DelayAvgTest'], \n",
    "#                       color=\"orangered\", \n",
    "#                       label=\"Delay test\", kde=True)\n",
    "#     plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_size = draw_data['NetSize'].unique()\n",
    "net_size.sort()\n",
    "fig = plt.figure(figsize=(20, 21))\n",
    "fig.suptitle('Neural Network \\n End2end delay estimates \\n', \n",
    "             fontsize=40,\n",
    "             fontweight='bold')\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "k = 1\n",
    "for i in net_size:\n",
    "    size = [1, 5, 10, 20]\n",
    "   \n",
    "    if i in size:\n",
    "        draw_hist = draw_data.loc[draw_data['NetSize']==i]\n",
    "        ax = fig.add_subplot(2, 2, k)\n",
    "        plt.title('Network size is ' + str(int(i)), fontweight='bold')\n",
    "        ax = sns.histplot(draw_hist.loc[:,'TreeDelayEst'], \n",
    "                          color=\"fuchsia\", \n",
    "                          label=\"Neural Network model\", kde=True)\n",
    "        ax = sns.histplot(draw_hist.loc[:,'DelayAvgTest'], \n",
    "                          color=\"orangered\", \n",
    "                          label=\"Delay test\", kde=True)\n",
    "        \n",
    "        \n",
    "        k += 1\n",
    "        plt.xlabel('Delays')\n",
    "plt.legend()\n",
    "plt.savefig('data/images/ann_histogram.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий график диаграммы рассеивания для всех регрессионных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [ls_delay_estimate, \n",
    "         tree_delay_estimate,\n",
    "         gtb_delay_estimate,\n",
    "         ann_delay_estimate]\n",
    "\n",
    "label = ['Least Squeare model',\n",
    "         'Decision tree model',\n",
    "         'Gradient Boosting model',\n",
    "         'Neural network model']\n",
    "column = ['LsDelayEst',\n",
    "          'TreeDelayEst',\n",
    "          'GTBDelayEst',\n",
    "          'AnnDelayEst']\n",
    "scatter_color = ['Greens',\n",
    "                 'autumn',\n",
    "                 'Blues',\n",
    "                 'PuRd']\n",
    "diag_line_color = ['aquamarine', \n",
    "                   'red',\n",
    "                   'dodgerblue',\n",
    "                   'pink']\n",
    "\n",
    "fig = plt.figure(figsize=(18, 18))\n",
    "plt.subplots_adjust(top=0.92)\n",
    "fig.suptitle('E2E Delay', fontsize=28, fontweight='bold')\n",
    "\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(2, 2, i+1)\n",
    "    ax.set_title(label[i], fontdict={'fontweight': 'bold'})\n",
    "    cm = plt.get_cmap(scatter_color[i])\n",
    "    col = [cm(float(i)/(len(ann_delay_estimate))) for i in range((len(ann_delay_estimate)))]\n",
    "    ax = plt.scatter(draw_data[column[i]], \n",
    "                 draw_data['DelayAvgTest'], \n",
    "                 c=col)\n",
    "#     plt.subplots_adjust(top=0.95)\n",
    "    plt.plot(x, x, \n",
    "             linestyle='-', \n",
    "             linewidth=2.4, \n",
    "             color=diag_line_color[i])\n",
    "    plt.xlim([0, 800])\n",
    "    plt.ylim([0, 800])\n",
    "    plt.xlabel(r'$Delay \\ Test$')\n",
    "    plt.ylabel(r'$Delay \\ Estimate$')\n",
    "    plt.grid()\n",
    "plt.savefig('data/images/total_scatter_diagram.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПОСТРОЕНИЕ ПРОГНОЗНОЙ МОДЕЛИ ВЕРОЯТНОСТИ ДОСТАВКИ ПАКЕТОВ В МНОГОФАЗНОЙ СЕТИ МАСОВОГО ОБСЛУЖИВАНИЯ С ЛИНЕЙНОЙ ТОПОЛОГИЕЙ\n",
    "\n",
    "В отличии от прогнозной модели времени межконцевой задержки, для которой мы строили регрессионную модель, для модели вероятности доставки нам не критично предсказывать конкретные значения. Гораздо важнее оценивать вероятность относительно граничного значения. Мы задаемся граничным условием `BOUNDARY` для условия успешной доставки. \n",
    "\n",
    "Будем классификать на две группы:\n",
    "- успешная доставка P $\\in$ \\[BOUNDARY, 1];\n",
    "- вероятность потери пакетов P $\\in$  [0, BOUNDARY).\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display \n",
    "display.Image(\"../experiments/data/images/clf_metrics.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики для задач классификации:\n",
    "\n",
    "_TP_ is true posistive;\n",
    "\n",
    "_TN_ is true negative;\n",
    "\n",
    "_FP_ is false positive;\n",
    "\n",
    "_FN_ is false negative.\n",
    "\n",
    "Для оценки моделей будем использовать следущие метрики:    \n",
    "   \n",
    "$$\n",
    "    1. \\ Precision = \\dfrac{TP}{TP + FP};\n",
    "$$\n",
    "\n",
    "$$\n",
    "    2. \\ Recall = \\dfrac{TP}{TP + FN};\n",
    "$$\n",
    "\n",
    "$$\n",
    "    3. \\ F_1 = 2 * \\dfrac{Precision * Recall}{Precision + Recall}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Модель задачи классификации на Дереве решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prepare classification model using Decision Tree algorithm\"\"\"\n",
    "def get_tree_classif_model(x_train, x_test, \n",
    "                           y_train, y_test, \n",
    "                           boundary=0.9, \n",
    "                           max_depth=10, \n",
    "                           splitter='best') -> Tuple[np.array, \n",
    "                                                     DecisionTreeClassifier, \n",
    "                                                     list, \n",
    "                                                     list]:\n",
    "    binary_train = [1 if i >= boundary else 0 for i in y_train]\n",
    "    binary_test = [1 if i >= boundary else 0 for i in y_test]\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, splitter=splitter)\n",
    "    clf = clf.fit(x_train, binary_train)\n",
    "    prob_estimate = clf.predict(x_test)\n",
    "    return prob_estimate, clf, binary_train, binary_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOUNDARY = 0.9 \n",
    "prob_clf_train = [1 if i > BOUNDARY else 0 for i in y_train['DeliveryProb']]\n",
    "prob_clf_test = [1 if i > BOUNDARY else 0 for i in y_test['DeliveryProb']]\n",
    "\n",
    "tree_prob_estimate, tree_clf, prob_clf_train, prob_clf_test = get_tree_classif_model(x_train, \n",
    "                                                                                     x_test, \n",
    "                                                                                     y_train['DeliveryProb'], \n",
    "                                                                                     y_test['DeliveryProb'],\n",
    "                                                                                     boundary=BOUNDARY)\n",
    "\n",
    "tree_prob_precision_score = '{:.3f}'.format(precision_score(prob_clf_test, tree_prob_estimate))\n",
    "tree_prob_recall_score = '{:.3f}'.format(recall_score(prob_clf_test, tree_prob_estimate))\n",
    "tree_prob_f1_score = '{:.3f}'.format(f1_score(prob_clf_test, tree_prob_estimate))\n",
    "print(tree_prob_precision_score)\n",
    "print(tree_prob_recall_score)\n",
    "print(tree_prob_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data['TreeDeliveryProbTest'] = y_test['DeliveryProb']\n",
    "draw_data['TreeDeliveryProbEst'] = tree_prob_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YLIM = [0.5, 1]\n",
    "# net_size = draw_data['NetSize'].unique()\n",
    "# net_size.sort()\n",
    "# fig = plt.figure(figsize=(22, 40))\n",
    "# fig.suptitle(r'Estimates of Delivery Packets Probability' + \n",
    "#              ' \\n $Presicion$ = {}\\n $Recall$ = {}\\n $F_1$ = {}'.format(\n",
    "#                 tree_prob_precision_score, \n",
    "#                 tree_prob_recall_score, \n",
    "#                 tree_prob_f1_score), fontsize=18)\n",
    "# plt.subplots_adjust(top=0.95)\n",
    "# for i in net_size:\n",
    "#     draw_plot = draw_data.loc[draw_data['NetSize']==i]\n",
    "#     ax = fig.add_subplot(5, 4,  int(i))\n",
    "    \n",
    "#     ax.title.set_text('Network size is ' + str(int(i)))    \n",
    "#     plt.ylim(YLIM)\n",
    "\n",
    "#     prob_color = ['limegreen' if i >BOUNDARY else 'orangered' for i in draw_plot['TreeDeliveryProbEst']]\n",
    "#     ax.scatter(draw_plot['TreeDeliveryProbTest'].index, draw_plot['TreeDeliveryProbTest'], \n",
    "#                color=prob_color)\n",
    "#     ax.add_patch(\n",
    "#      patches.Rectangle(\n",
    "#         (0, 0),\n",
    "#         width=draw_plot.loc[:,'TreeDeliveryProbTest'].index.max(),\n",
    "#         height=BOUNDARY,\n",
    "#         facecolor = 'coral',\n",
    "#         fill=True,\n",
    "#         alpha=0.3))\n",
    "#     ax.add_patch(\n",
    "#      patches.Rectangle(\n",
    "#         (0, BOUNDARY),\n",
    "#         width=draw_plot.loc[:,'TreeDeliveryProbTest'].index.max(),\n",
    "#         height=1 - BOUNDARY,\n",
    "#         facecolor = 'aquamarine',\n",
    "#         fill=True, alpha=0.3))\n",
    "\n",
    "#     plt.xticks(color='w')   \n",
    "#     ax.set_xlabel(r'$Test \\ Samples$')\n",
    "#     ax.set_ylabel(r'$Probability$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "YLIM = [0, 1]\n",
    "net_size = draw_data['NetSize'].unique()\n",
    "net_size.sort()\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "# fig.suptitle(r'Estimates of Delivery Packets Probability' + \n",
    "#              ' \\n $Presicion$ = {}\\n $Recall$ = {}\\n $F_1$ = {}'.format(\n",
    "#                 tree_prob_precision_score, \n",
    "#                 tree_prob_recall_score, \n",
    "#                 tree_prob_f1_score), fontsize=18)\n",
    "fig.suptitle(r' Decision Tree' + \n",
    "             ' \\n Estimates of Delivery Packets Probability', \n",
    "             fontsize=25,\n",
    "             fontweight='bold')\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1), fontsize=20)\n",
    "plt.xticks([]) \n",
    "k = 1\n",
    "for i in net_size:\n",
    "    size = [1, 5, 10, 20]\n",
    "    if i in size:\n",
    "        draw_plot = draw_data.loc[draw_data['NetSize']==i]\n",
    "        ax = fig.add_subplot(1, 4,  int(k))\n",
    "\n",
    "        plt.title('Network size is ' + str(int(i)), fontsize=20, fontweight='bold')    \n",
    "        plt.ylim(YLIM)\n",
    "\n",
    "        prob_color = ['limegreen' if i >BOUNDARY else 'orangered' for i in draw_plot['TreeDeliveryProbEst']]\n",
    "        ax.scatter(draw_plot['TreeDeliveryProbTest'].index, draw_plot['TreeDeliveryProbTest'], \n",
    "                   color=prob_color)\n",
    "        ax.add_patch(\n",
    "         patches.Rectangle(\n",
    "            (0, 0),\n",
    "            width=draw_plot.loc[:,'TreeDeliveryProbTest'].index.max(),\n",
    "            height=BOUNDARY,\n",
    "            facecolor = 'coral',\n",
    "            fill=True,\n",
    "            alpha=0.3))\n",
    "        ax.add_patch(\n",
    "         patches.Rectangle(\n",
    "            (0, BOUNDARY),\n",
    "            width=draw_plot.loc[:,'TreeDeliveryProbTest'].index.max(),\n",
    "            height=1 - BOUNDARY,\n",
    "            facecolor = 'aquamarine',\n",
    "            fill=True, alpha=0.3))\n",
    "\n",
    "        plt.xticks(color='w')   \n",
    "        ax.set_xlabel(r'$Test \\ Samples$')\n",
    "        ax.set_ylabel(r'$Probability$')\n",
    "        k += 1\n",
    "        plt.xticks(color='w')\n",
    "        plt.yticks(np.arange(0, 1.1, 0.1)) \n",
    "        ax.axis('off') \n",
    "\n",
    "plt.savefig('data/images/tree_clf_prob.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Модель задачи классификации на многослойном персептроне с алгоритмом Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prepare classification model using MLP algorithm\"\"\"\n",
    "def get_mlp_classif_model(x_train, x_test, \n",
    "                          y_train, y_test,\n",
    "                          boundary=0.9, \n",
    "                          solver='adam',\n",
    "                          activation='relu',\n",
    "                          hidden_layer_sizes=(16, 16, 16)) -> Tuple[np.array, \n",
    "                                                                  MLPClassifier,\n",
    "                                                                  list, list]:\n",
    "    \n",
    "    binary_train = [1 if i > boundary else 0 for i in y_train]\n",
    "    binary_test = [1 if i > boundary else 0 for i in y_test]\n",
    "\n",
    "    clf = MLPClassifier(solver=solver, activation=activation, \n",
    "                        hidden_layer_sizes=hidden_layer_sizes, \n",
    "                        max_iter=2000, learning_rate='adaptive'\n",
    "                        ).fit(x_train, binary_train)\n",
    "    prob_estimate = clf.predict(x_test)\n",
    "\n",
    "    return prob_estimate, clf, binary_train, binary_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOUNDARY = 0.9\n",
    "\n",
    "mlpc_prob_estimate, mlpc_clf, prob_clf_train, prob_clf_test = get_mlp_classif_model(train_normalize,             test_normalize,\n",
    "                                                                                    y_train['DeliveryProb'], \n",
    "                                                                                    y_test['DeliveryProb'],\n",
    "                                                                                    boundary=0.9, \n",
    "                                                                                    hidden_layer_sizes=(54, 54))\n",
    "mlpc_prob_precision_score = '{:.3f}'.format(precision_score(prob_clf_test, mlpc_prob_estimate))\n",
    "mlpc_prob_recall_score = '{:.3f}'.format(recall_score(prob_clf_test, mlpc_prob_estimate))\n",
    "mlpc_prob_f1_score = '{:.3f}'.format(f1_score(prob_clf_test, mlpc_prob_estimate))\n",
    "print(mlpc_prob_precision_score)\n",
    "print(mlpc_prob_recall_score)\n",
    "print(mlpc_prob_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data['MLPCDeliveryProbEst'] = mlpc_prob_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YLIM = [0.5, 1]\n",
    "# net_size = draw_data['NetSize'].unique()\n",
    "# net_size.sort()\n",
    "# fig = plt.figure(figsize=(22, 40))\n",
    "# fig.suptitle(\n",
    "#     'Estimates of Delivery Packets Probability \\n $Presicion$ = {}\\n $Recall$ = {}\\n $F_1$ = {}'.format(\n",
    "#         mlpc_prob_precision_score, \n",
    "#         mlpc_prob_recall_score, \n",
    "#         mlpc_prob_f1_score), \n",
    "#     fontsize=18)\n",
    "# plt.subplots_adjust(top=0.95)\n",
    "# for i in net_size:\n",
    "#     draw_plot = draw_data.loc[draw_data['NetSize']==i]\n",
    "#     ax = fig.add_subplot(5, 4,  int(i))\n",
    "#     ax.axhspan(0, .9, color='coral', zorder=0, alpha=0.3)\n",
    "#     ax.axhspan(.9, 1, color='aquamarine', zorder=0, alpha=0.3)\n",
    "#     ax.title.set_text('Network size is ' + str(int(i)))    \n",
    "#     plt.ylim(YLIM)\n",
    "\n",
    "#     prob_color = ['limegreen' if i >BOUNDARY else 'orangered' for i in draw_plot['MLPCDeliveryProbEst']]\n",
    "#     ax.scatter(draw_plot['TreeDeliveryProbTest'].index, draw_plot['TreeDeliveryProbTest'], \n",
    "#                color=prob_color)\n",
    "#     plt.xticks(color='w')\n",
    "#     plt.yticks(np.arange(0, 1.1, 0.1))   \n",
    "#     ax.set_xlabel(r'$Test \\ Samples$')\n",
    "#     ax.set_ylabel(r'$Probability$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YLIM = [0, 1]\n",
    "net_size = draw_data['NetSize'].unique()\n",
    "net_size.sort()\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "# fig.suptitle(r'Estimates of Delivery Packets Probability' + \n",
    "#              ' \\n $Presicion$ = {}\\n $Recall$ = {}\\n $F_1$ = {}'.format(\n",
    "#                 tree_prob_precision_score, \n",
    "#                 tree_prob_recall_score, \n",
    "#                 tree_prob_f1_score), fontsize=18)\n",
    "fig.suptitle(r' Neural Network' + \n",
    "             ' \\n Estimates of Delivery Packets Probability', \n",
    "             fontsize=25,\n",
    "             fontweight='bold')\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1), fontsize=20)\n",
    "plt.xticks([])\n",
    "k = 1\n",
    "for i in net_size:\n",
    "    size = [1, 5, 10, 20]\n",
    "    if i in size:\n",
    "        draw_plot = draw_data.loc[draw_data['NetSize']==i]\n",
    "        ax = fig.add_subplot(1, 4,  int(k))\n",
    "\n",
    "        plt.title('Network size is ' + str(int(i)), fontsize=20, fontweight='bold')    \n",
    "        plt.ylim(YLIM)\n",
    "\n",
    "        prob_color = ['limegreen' if i >BOUNDARY else 'orangered' for i in draw_plot['MLPCDeliveryProbEst']]\n",
    "        ax.scatter(draw_plot['TreeDeliveryProbTest'].index, draw_plot['TreeDeliveryProbTest'], \n",
    "                   color=prob_color)\n",
    "        ax.add_patch(\n",
    "         patches.Rectangle(\n",
    "            (0, 0),\n",
    "            width=draw_plot.loc[:,'TreeDeliveryProbTest'].index.max(),\n",
    "            height=BOUNDARY,\n",
    "            facecolor = 'coral',\n",
    "            fill=True,\n",
    "            alpha=0.3))\n",
    "        ax.add_patch(\n",
    "         patches.Rectangle(\n",
    "            (0, BOUNDARY),\n",
    "            width=draw_plot.loc[:,'TreeDeliveryProbTest'].index.max(),\n",
    "            height=1 - BOUNDARY,\n",
    "            facecolor = 'aquamarine',\n",
    "            fill=True, alpha=0.3))\n",
    "\n",
    "        plt.xticks(color='w')   \n",
    "        ax.set_xlabel(r'$Test \\ Samples$')\n",
    "        ax.set_ylabel(r'$Probability$')\n",
    "        k += 1\n",
    "        plt.xticks(color='w')\n",
    "        plt.yticks(np.arange(0, 1.1, 0.1))   \n",
    "        ax.axis('off') \n",
    "plt.savefig('data/images/ann_clf_prob.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Модель задачи классификации на градиентном бустинге с алгоритмом CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prepare classification model using Cat Boost algorithm\"\"\"\n",
    "def get_catboost_classif_model(x_train, x_test, \n",
    "                               y_train, y_test)-> Tuple[np.array, \n",
    "                                                        CatBoostClassifier, \n",
    "                                                        list, \n",
    "                                                        list]: \n",
    "    catboost_clf = CatBoostClassifier(iterations=1000,\n",
    "                                        learning_rate=0.1);\n",
    "    binary_train = [1 if i > BOUNDARY else 0 for i in y_train]\n",
    "    binary_test = [1 if i > BOUNDARY else 0 for i in y_test]\n",
    "    catboost_clf.fit(x_train, binary_train);\n",
    "    catboost_prob_estimate = catboost_clf.predict(x_test);\n",
    "    \n",
    "    return catboost_prob_estimate, catboost_clf, binary_train, binary_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "catboost_prob_estimate, catboost_clf, prob_clf_train, prob_clf_test = get_catboost_classif_model(\n",
    "    x_train, \n",
    "    x_test, \n",
    "    y_train['DeliveryProb'], \n",
    "    y_test['DeliveryProb'])\n",
    "\n",
    "catboost_prob_precision_score = '{:.3f}'.format(precision_score(prob_clf_test, catboost_prob_estimate))\n",
    "catboost_prob_recall_score = '{:.3f}'.format(recall_score(prob_clf_test, catboost_prob_estimate))\n",
    "catboost_prob_f1_score = '{:.3f}'.format(f1_score(prob_clf_test, catboost_prob_estimate))\n",
    "print(catboost_prob_precision_score)\n",
    "print(catboost_prob_recall_score)\n",
    "print(catboost_prob_f1_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data['CatBoostProbEst'] = catboost_prob_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YLIM = [0, 1]\n",
    "# net_size = draw_data['NetSize'].unique()\n",
    "# net_size.sort()\n",
    "# fig = plt.figure(figsize=(22, 40))\n",
    "# fig.suptitle(\n",
    "#     'Estimates of Delivery Packets Probability \\n $Presicion$ = {}\\n $Recall$ = {}\\n $F_1$ = {}'.format(\n",
    "#         catboost_prob_precision_score, \n",
    "#         catboost_prob_recall_score, \n",
    "#         catboost_prob_f1_score), \n",
    "#     fontsize=18)\n",
    "# plt.subplots_adjust(top=0.95)\n",
    "# for i in net_size:\n",
    "#     draw_plot = draw_data.loc[draw_data['NetSize']==i]\n",
    "#     ax = fig.add_subplot(5, 4,  int(i))\n",
    "#     ax.axhspan(0, .9, color='coral', zorder=0, alpha=0.3)\n",
    "#     ax.axhspan(.9, 1, color='aquamarine', zorder=0, alpha=0.3)\n",
    "#     ax.title.set_text('Network size is ' + str(int(i)))    \n",
    "#     plt.ylim(YLIM)\n",
    "\n",
    "#     prob_color = ['limegreen' if i >BOUNDARY else 'orangered' for i in draw_plot['CatBoostProbEst']]\n",
    "#     ax.scatter(draw_plot['TreeDeliveryProbTest'].index, draw_plot['TreeDeliveryProbTest'], \n",
    "#                color=prob_color)\n",
    "#     plt.xticks(color='w')\n",
    "#     plt.yticks(np.arange(0, 1.1, 0.1))   \n",
    "#     ax.set_xlabel(r'$Test \\ Samples$')\n",
    "#     ax.set_ylabel(r'$Probability$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YLIM = [0, 1]\n",
    "net_size = draw_data['NetSize'].unique()\n",
    "net_size.sort()\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "# fig.suptitle(r'Estimates of Delivery Packets Probability' + \n",
    "#              ' \\n $Presicion$ = {}\\n $Recall$ = {}\\n $F_1$ = {}'.format(\n",
    "#                 tree_prob_precision_score, \n",
    "#                 tree_prob_recall_score, \n",
    "#                 tree_prob_f1_score), fontsize=18)\n",
    "fig.suptitle(r' Gradient Boosting' + \n",
    "             ' \\n Estimates of Delivery Packets Probability', \n",
    "             fontsize=25,\n",
    "             fontweight='bold')\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1), fontsize=20)\n",
    "plt.xticks([]) \n",
    "k = 1\n",
    "for i in net_size:\n",
    "    size = [1, 5, 10, 20]\n",
    "    if i in size:\n",
    "        draw_plot = draw_data.loc[draw_data['NetSize']==i]\n",
    "        ax = fig.add_subplot(1, 4,  int(k))\n",
    "\n",
    "        plt.title('Network size is ' + str(int(i)), fontsize=20, fontweight='bold')    \n",
    "        plt.ylim(YLIM)\n",
    "\n",
    "        prob_color = ['limegreen' if i >BOUNDARY else 'orangered' for i in draw_plot['CatBoostProbEst']]\n",
    "        ax.scatter(draw_plot['TreeDeliveryProbTest'].index, draw_plot['TreeDeliveryProbTest'], \n",
    "                   color=prob_color)\n",
    "        ax.add_patch(\n",
    "         patches.Rectangle(\n",
    "            (0, 0),\n",
    "            width=draw_plot.loc[:,'TreeDeliveryProbTest'].index.max(),\n",
    "            height=BOUNDARY,\n",
    "            facecolor = 'coral',\n",
    "            fill=True,\n",
    "            alpha=0.3))\n",
    "        ax.add_patch(\n",
    "         patches.Rectangle(\n",
    "            (0, BOUNDARY),\n",
    "            width=draw_plot.loc[:,'TreeDeliveryProbTest'].index.max(),\n",
    "            height=1 - BOUNDARY,\n",
    "            facecolor = 'aquamarine',\n",
    "            fill=True, alpha=0.3))\n",
    "\n",
    "        plt.xticks(color='w')   \n",
    "        ax.set_xlabel(r'$Test \\ Samples$')\n",
    "        ax.set_ylabel(r'$Probability$')\n",
    "        k += 1\n",
    "        plt.xticks(color='w')\n",
    "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "        ax.axis('off')    \n",
    "plt.savefig('data/images/catboost_clf_prob.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Модель задачи классификации c помощью логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prepare classification model using Logistic Regression algorithm\"\"\"\n",
    "def get_logress_classif_model(x_train, x_test, \n",
    "                              y_train, y_test,\n",
    "                              boundary=0.9)-> Tuple[np.array, LogisticRegression,\n",
    "                                                    list, list]: \n",
    "    logres_model = LogisticRegression(max_iter=1000)\n",
    "    binary_train = [1 if i > boundary else 0 for i in y_train]\n",
    "    binary_test = [1 if i > boundary else 0 for i in y_test]\n",
    "    logres_model.fit(x_train, binary_train)\n",
    "    logres_prob_estimate = logres_model.predict(x_test)\n",
    "    \n",
    "    return logres_prob_estimate, logres_model, binary_train, binary_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logres_prob_estimate, logres_model, prob_clf_train, prob_clf_test = get_logress_classif_model(x_train, \n",
    "                                                                                x_test, \n",
    "                                                                                y_train['DeliveryProb'], \n",
    "                                                                                y_test['DeliveryProb'],\n",
    "                                                                                boundary=BOUNDARY)\n",
    "\n",
    "logres_prob_precision_score = '{:.3f}'.format(precision_score(prob_clf_test, logres_prob_estimate))\n",
    "logres_prob_recall_score = '{:.3f}'.format(recall_score(prob_clf_test, logres_prob_estimate))\n",
    "logres_prob_f1_score = '{:.3f}'.format(f1_score(prob_clf_test, logres_prob_estimate))\n",
    "print(logres_prob_precision_score)\n",
    "print(logres_prob_recall_score)\n",
    "print(logres_prob_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data['LogResProbEst'] = logres_prob_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YLIM = [0, 1]\n",
    "net_size = draw_data['NetSize'].unique()\n",
    "net_size.sort()\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "# fig.suptitle(r'Estimates of Delivery Packets Probability' + \n",
    "#              ' \\n $Presicion$ = {}\\n $Recall$ = {}\\n $F_1$ = {}'.format(\n",
    "#                 tree_prob_precision_score, \n",
    "#                 tree_prob_recall_score, \n",
    "#                 tree_prob_f1_score), fontsize=18)\n",
    "fig.suptitle(r'Logistic Regression' + \n",
    "             ' \\n Estimates of Delivery Packets Probability', \n",
    "             fontsize=25,\n",
    "             fontweight='bold')\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1), fontsize=20)\n",
    "plt.xticks([]) \n",
    "k = 1\n",
    "for i in net_size:\n",
    "    size = [1, 5, 10, 20]\n",
    "    if i in size:\n",
    "        draw_plot = draw_data.loc[draw_data['NetSize']==i]\n",
    "        ax = fig.add_subplot(1, 4,  int(k))\n",
    "\n",
    "        plt.title('Network size is ' + str(int(i)), fontsize=20, fontweight='bold')    \n",
    "        plt.ylim(YLIM)\n",
    "\n",
    "        prob_color = ['limegreen' if i >BOUNDARY else 'orangered' for i in draw_plot['LogResProbEst']]\n",
    "        ax.scatter(draw_plot['TreeDeliveryProbTest'].index, draw_plot['TreeDeliveryProbTest'], \n",
    "                   color=prob_color)\n",
    "        ax.add_patch(\n",
    "         patches.Rectangle(\n",
    "            (0, 0),\n",
    "            width=draw_plot.loc[:,'TreeDeliveryProbTest'].index.max(),\n",
    "            height=BOUNDARY,\n",
    "            facecolor = 'coral',\n",
    "            fill=True,\n",
    "            alpha=0.3))\n",
    "        ax.add_patch(\n",
    "         patches.Rectangle(\n",
    "            (0, BOUNDARY),\n",
    "            width=draw_plot.loc[:,'TreeDeliveryProbTest'].index.max(),\n",
    "            height=1 - BOUNDARY,\n",
    "            facecolor = 'aquamarine',\n",
    "            fill=True, alpha=0.3))\n",
    "\n",
    "        plt.xticks(color='w')   \n",
    "        ax.set_xlabel(r'$Test \\ Samples$')\n",
    "        ax.set_ylabel(r'$Probability$')\n",
    "        k += 1\n",
    "        plt.xticks(color='w')\n",
    "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "        ax.axis('off')    \n",
    "plt.savefig('data/images/logres_clf_prob.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все модели классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YLIM = [0, 1]\n",
    "column_name = ['LogResProbEst', 'TreeDeliveryProbEst','CatBoostProbEst', 'MLPCDeliveryProbEst']\n",
    "title_name = ['Logistic Regression', 'Decision Tree', 'Gradient Boosting', 'Neural Network']\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "fig.suptitle('Classification', \n",
    "             fontsize=40,\n",
    "             fontweight='bold')\n",
    "plt.yticks(np.arange(0, 1.1, 0.1), fontsize=20) \n",
    "plt.xlabel(r'$Test \\ Samples$')\n",
    "plt.ylabel(r'$Probability$') \n",
    "plt.tick_params(\n",
    "        axis='both',          \n",
    "        which='both',     \n",
    "        bottom=False,      \n",
    "        top=False,     \n",
    "        labelbottom=False,\n",
    "        left=False)\n",
    "\n",
    "for i in range(len(column_name)):\n",
    "\n",
    "    ax = fig.add_subplot(1, 4,  int(i+1))\n",
    "\n",
    "    plt.title(str(title_name[i]), fontsize=22, fontweight='bold')    \n",
    "    plt.ylim(YLIM)\n",
    "\n",
    "    prob_color = ['limegreen' if i >BOUNDARY else 'orangered' for i in draw_data[column_name[i]]]\n",
    "    ax.scatter(draw_data['TreeDeliveryProbTest'].index, draw_data['TreeDeliveryProbTest'], \n",
    "                color=prob_color)\n",
    "    ax.add_patch(\n",
    "        patches.Rectangle(\n",
    "        (0, 0),\n",
    "        width=draw_data.loc[:,'TreeDeliveryProbTest'].index.max(),\n",
    "        height=BOUNDARY,\n",
    "        facecolor = 'coral',\n",
    "        fill=True,\n",
    "        alpha=0.3))\n",
    "    ax.add_patch(\n",
    "        patches.Rectangle(\n",
    "        (0, BOUNDARY),\n",
    "        width=draw_data.loc[:,'TreeDeliveryProbTest'].index.max(),\n",
    "        height=1 - BOUNDARY,\n",
    "        facecolor = 'aquamarine',\n",
    "        fill=True, alpha=0.3))\n",
    "  \n",
    "    ax.set_xlabel(r'$Test \\ Samples$')\n",
    "    ax.set_ylabel(r'$Probability$')\n",
    "\n",
    "    ax.axis('off')\n",
    "plt.savefig('data/images/total_clf_prob.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили прогнозные модели времени межконцевой задержки и вероятности доставки пакетов в тандемности сети. Проверим адекватность моделей для тестовых данных:\n",
    "- для различных коэффициентов загрузок $\\rho$;\n",
    "- для различных длин тандема."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценки времени задержки и вероятности доставки пакетов от коэффициента загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = (\n",
    "    'ArrM1',\n",
    "    'ArrM2',\n",
    "    'ArrM3',\n",
    "    'ArrAvg', \n",
    "    'ArrStd', \n",
    "    'ArrCv',\n",
    "    'ArrSkewness',\n",
    "    'SrvM1',\n",
    "    'SrvM2',\n",
    "    'SrvM3',\n",
    "    'SrvAvg', \n",
    "    'SrvStd', \n",
    "    'SrvCv',\n",
    "    'SrvSkewness', \n",
    "    'Rho', \n",
    "    'NetSize', \n",
    "    'Capacity', \n",
    "    'NumPackets',\n",
    "    'DelayAvg', \n",
    "    'DelayStd', \n",
    "    'DeliveryProb',\n",
    ")\n",
    "\n",
    "arr_m1 = [np.random.uniform(0, 10)]\n",
    "arr_cv = [np.random.uniform(0.5, 3)]\n",
    "\n",
    "rho =  np.arange(0.1, 1, 0.05)\n",
    "\n",
    "srv_cv = [np.random.uniform(0.5, 3)]\n",
    "\n",
    "net_size = np.arange(1, 20+1)\n",
    "capacity = [10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_rho_netsize = pd.DataFrame(columns=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPEAT = True\n",
    "start_time = time.time()\n",
    "if REPEAT:\n",
    "    for _arr_m1, _arr_cv, _rho, \\\n",
    "        _srv_cv, _net_size, _capacity in tqdm(product(arr_m1, arr_cv, \\\n",
    "            rho, srv_cv, net_size, capacity)):\n",
    "\n",
    "            _arr_skewness = np.random.uniform(_arr_cv - 1/_arr_cv, 100)\n",
    "            _srv_m1 = _rho * _arr_m1\n",
    "            _srv_skewness = np.random.uniform(_srv_cv - 1/_srv_cv, 100)\n",
    "\n",
    "            sim_data_rho_netsize = simulate(\n",
    "                sim_data_rho_netsize,\n",
    "                arr_m1=_arr_m1,\n",
    "                arr_m2=get_noncentral_m2(_arr_m1, _arr_cv),\n",
    "                arr_m3=get_noncentral_m3(_arr_m1, _arr_cv, _arr_skewness),\n",
    "                srv_m1=_srv_m1,\n",
    "                srv_m2=get_noncentral_m2(_srv_m1, _srv_cv),\n",
    "                srv_m3=get_noncentral_m3(_srv_m1, _srv_cv, _srv_skewness),\n",
    "                net_size=_net_size,\n",
    "                capacity=_capacity,\n",
    "                num_packets=NUM_PACKETS,\n",
    "                force=FORCE_SIMULATION\n",
    "            )\n",
    "    print(f'Evaluation time = {time.time() - start_time}')\n",
    "    print(sim_data_rho_netsize.info())\n",
    "    print(sim_data_rho_netsize)\n",
    "\n",
    "    sim_data_rho_netsize.to_csv('./data/Tandem_network_data_with_different_rho_and_netsize.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_rho_netsize = pd.read_csv('./data/Tandem_network_data_with_different_rho_and_netsize.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\n",
    "    'ArrM1',\n",
    "    'ArrM2',\n",
    "    'ArrM3',\n",
    "    'SrvM1',\n",
    "    'SrvM2',\n",
    "    'SrvM3',\n",
    "    'NetSize', \n",
    "    'Capacity',\n",
    "    ]\n",
    "x_test_rho_netsize = sim_data_rho_netsize.loc[:, COLUMNS]\n",
    "x_test_rho_netsize\n",
    "y_test_delay = sim_data_rho_netsize['DelayAvg']\n",
    "y_test_prob = sim_data_rho_netsize['DeliveryProb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_metrics(test, estimate) -> Tuple[float, float, float]:\n",
    "    r = corr(test, estimate)\n",
    "    _std = std(test, estimate)\n",
    "    # mse = mean_squared_error(test, estimate)\n",
    "    r2 = r2_score(test, estimate)\n",
    "    return r, _std, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_metrics(test, estimate) -> Tuple[float, float, float]:\n",
    "    precision = precision_score(test, estimate)\n",
    "    recall = recall_score(test, estimate)\n",
    "    f1 = f1_score(test, estimate)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прогнозирование времени задержек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "ls_rho_netsize_estimate = ls.predict(x_test_rho_netsize)\n",
    "R, STD, R2 = get_regression_metrics(y_test_delay, ls_rho_netsize_estimate)\n",
    "print(f'R = {R:.3f}')\n",
    "print(f'STD = {STD:.3f}')\n",
    "print(f'R2 = {R2:.3f}')\n",
    "sim_data_rho_netsize['ls_estimate'] = ls_rho_netsize_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "tree_rho_netsize_estimate = tree_reg.predict(x_test_rho_netsize)\n",
    "R, STD, R2 = get_regression_metrics(y_test_delay, tree_rho_netsize_estimate)\n",
    "print(f'R = {R:.3f}')\n",
    "print(f'STD = {STD:.3f}')\n",
    "print(f'R2 = {R2:.3f}')\n",
    "sim_data_rho_netsize['tree_estimate'] = tree_rho_netsize_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "gtb_rho_netsize_estimate = gtb.predict(x_test_rho_netsize)\n",
    "R, STD, R2 = get_regression_metrics(y_test_delay, gtb_rho_netsize_estimate)\n",
    "print(f'R = {R:.3f}')\n",
    "print(f'STD = {STD:.3f}')\n",
    "print(f'R2 = {R2:.3f}')\n",
    "sim_data_rho_netsize['gtb_estimate'] = gtb_rho_netsize_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "test_normalize = normalize(x_test_rho_netsize, \n",
    "                           simulation_data.loc[:,COLUMNS].describe())\n",
    "ann_rho_netsize_estimate = ann.predict(test_normalize).flatten()\n",
    "R, STD, MSE = get_regression_metrics(y_test_delay, ann_rho_netsize_estimate)\n",
    "print(f'R = {R:.3f}')\n",
    "print(f'STD = {STD:.3f}')\n",
    "print(f'MSE = {MSE:.3f}')\n",
    "sim_data_rho_netsize['ann_estimate'] = ann_rho_netsize_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_size = sim_data_rho_netsize['NetSize'].unique()\n",
    "# net_size.sort()\n",
    "# fig = plt.figure(figsize=(20, 50))\n",
    "# fig.suptitle('End2end delay estimates \\n', fontsize=16)\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "# for i in net_size:\n",
    "#     draw = sim_data_rho_netsize.loc[sim_data_rho_netsize['NetSize']==i]\n",
    "#     ax = fig.add_subplot(10, 2, int(i))\n",
    "#     ax.title.set_text('Network size is ' + str(int(i)))    \n",
    "#     plt.plot(draw['Rho'], draw['DelayAvg'], '-D', \n",
    "#              color='chocolate', label='Delay test',\n",
    "#              linewidth=6, markersize=10)\n",
    "#     plt.plot(draw['Rho'], draw['ls_estimate'], '-o', color=\"mediumseagreen\",\n",
    "#              linewidth=2, markersize=8, \n",
    "#              label='Least Squares estimate')\n",
    "#     plt.plot(draw['Rho'], draw['tree_estimate'], '-o', color=\"gold\", \n",
    "#              linewidth=2, markersize=8, \n",
    "#              label='Decision Tree estimate')\n",
    "#     plt.plot(draw['Rho'], draw['gtb_estimate'], '-o', color=\"mediumblue\", \n",
    "#              linewidth=2, markersize=8, \n",
    "#              label='Gradient Tree Boosting estimate')\n",
    "#     plt.plot(draw['Rho'], draw['ann_estimate'], '-o', color=\"fuchsia\",\n",
    "#              linewidth=2, markersize=8, \n",
    "#              label='Artificial Neural Network estimate')\n",
    "#     plt.xticks(np.arange(0, 1, 0.1))  \n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.xlabel(r'$\\rho$')\n",
    "#     plt.ylabel(r'$Delay$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_size = sim_data_rho_netsize['NetSize'].unique()\n",
    "net_size.sort()\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "fig.suptitle('End2end delay estimates \\n', fontsize=40, fontweight='bold')\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "size = [1, 5, 10, 20 ]\n",
    "k = 1\n",
    "for i in net_size:\n",
    "    if i in size:\n",
    "        draw = sim_data_rho_netsize.loc[sim_data_rho_netsize['NetSize']==i]\n",
    "        ax = fig.add_subplot(2, 2, k)\n",
    "        ax.set_title('Network size is ' + str(int(i)), fontdict={'fontweight': 'bold'})    \n",
    "        plt.plot(draw['Rho'], draw['DelayAvg'], '-D', \n",
    "                color='chocolate', label='Delay test',\n",
    "                linewidth=6, markersize=10)\n",
    "        plt.plot(draw['Rho'], draw['ls_estimate'], '-o', color=\"mediumseagreen\",\n",
    "                linewidth=2, markersize=8, \n",
    "                label='Least Squares estimate')\n",
    "        plt.plot(draw['Rho'], draw['tree_estimate'], '-o', color=\"gold\", \n",
    "                linewidth=2, markersize=8, \n",
    "                label='Decision Tree estimate')\n",
    "        plt.plot(draw['Rho'], draw['gtb_estimate'], '-o', color=\"mediumblue\", \n",
    "                linewidth=2, markersize=8, \n",
    "                label='Gradient Tree Boosting estimate')\n",
    "        plt.plot(draw['Rho'], draw['ann_estimate'], '-o', color=\"fuchsia\",\n",
    "                linewidth=2, markersize=8, \n",
    "                label='Artificial Neural Network estimate')\n",
    "        plt.xticks(np.arange(0, 1, 0.1))  \n",
    "        plt.legend(fontsize=12)\n",
    "        plt.grid()\n",
    "        plt.xlabel(r'$\\rho$')\n",
    "        plt.ylabel(r'$Delay$')\n",
    "        k += 1\n",
    "\n",
    "plt.savefig('data/images/rho_total_delay_est.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прогнозирование вероятности доставки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_prob_test = [1 if i > BOUNDARY else 0 for i in y_test_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "logres_prob_rho_netsize_estimate = logres_model.predict(x_test_rho_netsize)\n",
    "Precision, Recall, F1 = get_classification_metrics(binary_prob_test, \n",
    "                                                   logres_prob_rho_netsize_estimate)\n",
    "print(f'Precision = {Precision:.3f}')\n",
    "print(f'Recall = {Recall:.3f}')\n",
    "print(f'F1 = {F1:.3f}')\n",
    "sim_data_rho_netsize['logres_prob_estimate'] = logres_prob_rho_netsize_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "tree_prob_rho_netsize_estimate = tree_clf.predict(x_test_rho_netsize)\n",
    "Precision, Recall, F1 = get_classification_metrics(binary_prob_test, \n",
    "                                                   tree_prob_rho_netsize_estimate)\n",
    "print(f'Precision = {Precision:.3f}')\n",
    "print(f'Recall = {Recall:.3f}')\n",
    "print(f'F1 = {F1:.3f}')\n",
    "sim_data_rho_netsize['tree_prob_estimate'] = tree_prob_rho_netsize_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "catboost_prob_rho_netsize_estimate = catboost_clf.predict(x_test_rho_netsize)\n",
    "Precision, Recall, F1 = get_classification_metrics(binary_prob_test, \n",
    "                                                   catboost_prob_rho_netsize_estimate)\n",
    "print(f'Precision = {Precision:.3f}')\n",
    "print(f'Recall = {Recall:.3f}')\n",
    "print(f'F1 = {F1:.3f}')\n",
    "sim_data_rho_netsize['catboost_prob_estimate'] = catboost_prob_rho_netsize_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "test_prob_rho_normalize = normalize(x_test_rho_netsize, \n",
    "                                    simulation_data.loc[:,COLUMNS].describe())\n",
    "ann_prob_rho_netsize_estimate = mlpc_clf.predict(test_prob_rho_normalize)\n",
    "Precision, Recall, F1 = get_classification_metrics(binary_prob_test, \n",
    "                                                   ann_prob_rho_netsize_estimate)\n",
    "print(f'Precision = {Precision:.3f}')\n",
    "print(f'Recall = {Recall:.3f}')\n",
    "print(f'F1 = {F1:.3f}')\n",
    "sim_data_rho_netsize['ann_prob_estimate'] = ann_prob_rho_netsize_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['Logistic Regression model',\n",
    "         'Decision tree model',\n",
    "         'Gradient Boosting model',\n",
    "         'Neural network model']\n",
    "label[0].replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label = ['Logistic Regression model',\n",
    "         'Decision tree model',\n",
    "         'Gradient Boosting model',\n",
    "         'Neural network model']\n",
    "for j in label:\n",
    "\n",
    "    net_size = sim_data_rho_netsize['NetSize'].unique()\n",
    "    net_size.sort()\n",
    "    fig = plt.figure(figsize=(20, 18))\n",
    "\n",
    "    fig.suptitle(j, fontsize=40, fontweight='bold')\n",
    "    size = [1, 5, 10, 20]\n",
    "\n",
    "    k = 1\n",
    "    for i in net_size:\n",
    "        if i in size:\n",
    "        \n",
    "            draw = sim_data_rho_netsize.loc[sim_data_rho_netsize['NetSize']==i]\n",
    "            prob_color = ['limegreen' if i > BOUNDARY \n",
    "                        else 'orangered' \n",
    "                        for i in draw['catboost_prob_estimate']]\n",
    "            ax = fig.add_subplot(2, 2, int(k))\n",
    "            plt.yticks(np.arange(0.5, 1.1, 0.1), fontsize=18)  \n",
    "            plt.title('Network size is ' + str(int(i)), fontweight='bold')\n",
    "            plt.plot(draw['Rho'], draw['DeliveryProb'], '-', color=\"dimgray\",\n",
    "                    linewidth=2, markersize=4, marker='x', \n",
    "                    label=j)    \n",
    "            ax.scatter(draw['Rho'], draw['DeliveryProb'], \n",
    "                    label='Delivery Packets Probability test',\n",
    "                    color=prob_color, s=150)\n",
    "            ax.hlines(BOUNDARY, 0, 1, color='r')\n",
    "            ax.add_patch(\n",
    "            patches.Rectangle(\n",
    "                (0, 0.6),\n",
    "                width=1,\n",
    "                height=BOUNDARY - 0.5,\n",
    "                facecolor = 'coral',\n",
    "                fill=True,\n",
    "                alpha=0.3))\n",
    "            ax.add_patch(\n",
    "            patches.Rectangle(\n",
    "                (0, BOUNDARY),\n",
    "                width=1,\n",
    "                height=1 - BOUNDARY,\n",
    "                facecolor = 'aquamarine',\n",
    "                fill=True, alpha=0.3))\n",
    "            plt.xticks(np.arange(0, 1, 0.1), fontsize=18)  \n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.xlabel(r'$\\rho$')\n",
    "            plt.ylabel(r'$Probability$')\n",
    "            k += 1\n",
    "    plt.savefig('data/images/rho_total_prob_est_'+ j.replace(' ', '_') +'.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_metrics(df: pd.DataFrame, j:int, \n",
    "#                   model_name:str, portion:float, samples: int, \n",
    "#                   regress: Tuple[float,float, float]=tuple(), \n",
    "#                   classification: Tuple[float, float, float]=tuple()) -> Tuple[pd.DataFrame, int]:\n",
    "#     if len(classification) == 0:\n",
    "#         df.loc[j, 'Model'] = model_name\n",
    "#         df.loc[j, 'R'] = regress[0]\n",
    "#         df.loc[j, 'STD'] = regress[1]\n",
    "#         df.loc[j, 'R2'] = regress[2]\n",
    "#         df.loc[j, 'Portion'] = portion\n",
    "#         df.loc[j, 'NumSamples'] =  count\n",
    "#     else:\n",
    "#         df.loc[j, 'Model'] = model_name\n",
    "#         df.loc[j, 'Precision'] = classification[0]\n",
    "#         df.loc[j, 'Recall'] = classification[1]\n",
    "#         df.loc[j, 'F1'] = classification[2]\n",
    "#         df.loc[j, 'Portion'] = portion\n",
    "#         df.loc[j, 'NumSamples'] =  count\n",
    "\n",
    "#     return df, j+1\n",
    "\n",
    "\n",
    "# def get_average_metrics(model, x_test, y_test, task, \n",
    "#                         ann_test=None, n=1000) -> Tuple[float, float, float]:\n",
    "#     metric1 = np.zeros(n)\n",
    "#     metric2 = np.zeros(n)\n",
    "#     metric3 = np.zeros(n)\n",
    "\n",
    "#     for i in range(n):\n",
    "#         if ann_test is not None:\n",
    "#             estimate = model.predict(ann_test).flatten()\n",
    "#         else:\n",
    "#             estimate = model.predict(x_test)\n",
    "#         if task == 'regression':\n",
    "#             metric1[i], metric2[i], metric3[i] = get_regression_metrics(y_test, \n",
    "#                                                                         estimate)\n",
    "#         if task == 'classification':\n",
    "#             metric1[i], metric2[i], metric3[i] = get_classification_metrics(y_test, \n",
    "#                                                                             estimate)\n",
    "\n",
    "#     return metric1.mean(), metric2.mean(), metric3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_data_rho_netsize = pd.read_csv('./data/Tandem_network_data_with_different_rho_and_netsize.csv')\n",
    "# x_test = sim_data_rho_netsize.loc[:, COLUMNS]\n",
    "# y_test = sim_data_rho_netsize.loc[:, ['DelayAvg', 'DeliveryProb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COLUMNS = [\n",
    "#     'ArrM1',\n",
    "#     'ArrM2',\n",
    "#     'ArrM3',\n",
    "#     'SrvM1',\n",
    "#     'SrvM2',\n",
    "#     'SrvM3',\n",
    "#     'NetSize', \n",
    "#     'Capacity',\n",
    "#     ]\n",
    "\n",
    "# BOUNDARY = 0.9\n",
    "\n",
    "# r_model = {'liner_regresson': ls,\n",
    "#            'decision_tree': tree_reg, \n",
    "#            'gradient_boosting': gtb,\n",
    "#            'neural_network': ann}\n",
    "# r_metrics_column = ['Model', 'R', 'STD', 'MSE', \n",
    "#                     'Portion', 'NumSamples']\n",
    "# c_model = {'logistic_regression': logres_model,\n",
    "#             'decision_tree': tree_clf,\n",
    "#             'neural_network': mlpc_clf, \n",
    "#             'cat_boost': catboost_clf}\n",
    "# c_metrics_column = ['Model', 'Precision', 'Recall', 'F1'mns=r_metrics_column)\n",
    "# # c_metrics = pd.DataFrame(\n",
    "# #     np.zeros([len(data_portion)*len(c_model), len(c_metrics_column)]), \n",
    "# #     columns=c_metrics_column)\n",
    "\n",
    "# # c_index=0\n",
    "# # r_index=0\n",
    "\n",
    "# sim_data_rho_netsize = pd.read_csv('./data/Tandem_network_data_with_different_rho_and_netsize.csv')\n",
    "# sim_x_test = sim_data_rho_netsize.loc[:, COLUMNS]\n",
    "# sim_y_test = sim_data_rho_netsize.loc[:, ['DelayAvg', 'DeliveryProb']]\n",
    "\n",
    "# data = pd.read_csv('data/Tandem_network_with_ph_distribution.csv', index_col='Id')\n",
    "# data = data[data['Rho'] <= 10]\n",
    "\n",
    "# data_portion = [.001, .005, .01, .02, .03, .04, .05, .1, .2, .3, .4, .5, .6, .7, .75, .8, .85, .9, .93, .96, 1]\n",
    "# # data_portion = [.1, .2, .9]\n",
    "# r_metrics = pd.DataFrame(\n",
    "#     np.zeros([len(data_portion)*len(r_model), len(r_metrics_column)]), \n",
    "#     columns=r_metrics_column)\n",
    "# x_test = sim_data_rho_netsize.loc[:, COLUMNS]\n",
    "# y_test = sim_data_rho_netsize.loc[:, ['DelayAvg', 'DeliveryProb']]\n",
    "# c_metrics = pd.DataFrame(\n",
    "#     np.zeros([len(data_portion)*len(c_model), len(c_metrics_column)]), \n",
    "#     columns=c_metrics_column)\n",
    "\n",
    "# c_index=0\n",
    "# r_index=0\n",
    "                    \n",
    "# REPEAT = FALSE\n",
    "# if REPEAT:\n",
    "#     for portion in tqdm(data_portion):\n",
    "#         count = round(len(data.index)*portion)\n",
    "#         row = random.sample(list(data.index), count)\n",
    "#         sim = data.loc[row, :]\n",
    "\n",
    "#         sim_x_train = sim.loc[:, COLUMNS]\n",
    "#         sim_y_train = sim.loc[:, ['DelayAvg', 'DeliveryProb']]\n",
    "\n",
    "\n",
    "#         #  REGRESSION\n",
    "#         # linear regression\n",
    "#         _, ls = get_ls_regression_model(sim_x_train, sim_x_test, \n",
    "#                                         sim_y_train['DelayAvg'], \n",
    "#                                         sim_y_test['DelayAvg'])\n",
    "#         R, STD, MSE = get_average_metrics(ls, sim_x_test, \n",
    "#                                           sim_y_test['DelayAvg'], \n",
    "#                                           task='regression')\n",
    "#         r_metrics, r_index = write_metrics(r_metrics, r_index, \n",
    "#                                            'linear_regresson', \n",
    "#                                            portion, count, \n",
    "#                                            regress=(R, STD, MSE))\n",
    "#         # decision tree\n",
    "#         _, tree_reg = get_tree_regression_model(sim_x_train, sim_x_test, \n",
    "#                                                 sim_y_train['DelayAvg'], \n",
    "#                                                 sim_y_test['DelayAvg'])\n",
    "#         R, STD, MSE = get_average_metrics(tree_reg, sim_x_test, \n",
    "#                                           sim_y_test['DelayAvg'], \n",
    "#                                           task='regression')\n",
    "#         r_metrics, r_index = write_metrics(r_metrics, r_index, \n",
    "#                                            'decision_tree', \n",
    "#                                            portion, count, \n",
    "#                                            regress=(R, STD, MSE))\n",
    "#         # gradient boosting\n",
    "#         _, gtb = get_tree_regression_model(sim_x_train, sim_x_test, \n",
    "#                                            sim_y_train['DelayAvg'], \n",
    "#                                            sim_y_test['DelayAvg'])\n",
    "#         R, STD, MSE = get_average_metrics(gtb, sim_x_test, \n",
    "#                                           sim_y_test['DelayAvg'], \n",
    "#                                           task='regression')\n",
    "#         r_metrics, r_index = write_metrics(r_metrics, r_index, \n",
    "#                                            'gradient_boosting', \n",
    "#                                            portion, count, \n",
    "#                                            regress=(R, STD, MSE))\n",
    "#         # artificial neural network\n",
    "#         sim_train_normalize = normalize(sim_x_train, data.loc[:,COLUMNS].describe())\n",
    "#         sim_train_normalize.to_numpy();\n",
    "#         sim_test_normalize = normalize(sim_x_test, data.loc[:,COLUMNS].describe())\n",
    "#         sim_test_normalize.to_numpy();\n",
    "#         _, ann = get_ann_regression_model(sim_train_normalize, sim_test_normalize,\n",
    "#                                           sim_y_train['DelayAvg'], sim_y_test['DelayAvg'],\n",
    "#                                           size=len(sim.loc[:,COLUMNS].keys()))\n",
    "#         R, STD, MSE = get_average_metrics(ann, sim_x_test, \n",
    "#                                           sim_y_test['DelayAvg'], \n",
    "#                                           task='regression',\n",
    "#                                           ann_test=sim_test_normalize)\n",
    "#         r_metrics, r_index = write_metrics(r_metrics, r_index, \n",
    "#                                            'neural_network', \n",
    "#                                            portion, count, \n",
    "#                                            regress=(R, STD, MSE))\n",
    "\n",
    "\n",
    "#         # CLASSIFICATION\n",
    "#         # Logistic regression\n",
    "#         _, logres_model, _, prob_clf_test = get_logress_classif_model(sim_x_train, sim_x_test, \n",
    "#                                                                       sim_y_train['DeliveryProb'], \n",
    "#                                                                       sim_y_test['DeliveryProb'],\n",
    "#                                                                       boundary=BOUNDARY)\n",
    "\n",
    "#         precision, recall, f1 = get_average_metrics(logres_model, sim_x_test, prob_clf_test, task='classification')\n",
    "#         c_metrics, c_index = write_metrics(c_metrics, c_index, \n",
    "#                                            'logistic_regression', \n",
    "#                                            portion, count, \n",
    "#                                            classification=(precision, recall, f1))\n",
    "\n",
    "#         # Decision tree\n",
    "#         _, tree_clf, _, prob_clf_test = get_tree_classif_model(sim_x_train, \n",
    "#                                                                sim_x_test, \n",
    "#                                                                sim_y_train['DeliveryProb'], \n",
    "#                                                                sim_y_test['DeliveryProb'])\n",
    "\n",
    "#         precision, recall, f1 = get_average_metrics(tree_clf, sim_x_test, prob_clf_test, task='classification')\n",
    "\n",
    "#         c_metrics, c_index = write_metrics(c_metrics, c_index, \n",
    "#                                            'decision_tree', \n",
    "#                                            portion, count, \n",
    "#                                            classification=(precision, recall, f1))\n",
    "#         # Neural network\n",
    "#         _, mlpc_clf, _, prob_clf_test = get_mlp_classif_model(sim_x_train, \n",
    "#                                                               sim_x_test, \n",
    "#                                                               sim_y_train['DeliveryProb'], \n",
    "#                                                               sim_y_test['DeliveryProb'],\n",
    "#                                                               boundary=BOUNDARY, \n",
    "#                                                               hidden_layer_sizes=(54, 54))\n",
    "\n",
    "#         precision, recall, f1 = get_average_metrics(mlpc_clf, sim_x_test, prob_clf_test, task='classification')\n",
    "\n",
    "#         c_metrics, c_index = write_metrics(c_metrics, c_index, \n",
    "#                                            'neural_network', \n",
    "#                                            portion, count, \n",
    "#                                            classification=(precision, recall, f1))\n",
    "\n",
    "#         # Cat Boost\n",
    "#         _, catboost_clf, _, prob_clf_test = get_catboost_classif_model(sim_x_train, \n",
    "#                                                                        sim_x_test, \n",
    "#                                                                        sim_y_train['DeliveryProb'], \n",
    "#                                                                        sim_y_test['DeliveryProb'])\n",
    "\n",
    "#         precision, recall, f1 = get_average_metrics(catboost_clf, sim_x_test, prob_clf_test, task='classification')\n",
    "\n",
    "#         c_metrics, c_index = write_metrics(c_metrics, c_index, \n",
    "#                                            'cat_boost', \n",
    "#                                            portion, count, \n",
    "#                                            classification=(precision, recall, f1))                                   \n",
    "\n",
    "#     r_metrics.to_csv('./data/Regression_metrics.csv')\n",
    "#     c_metrics.to_csv('./data/Classification_metrics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_metrics = pd.read_csv('./data/Regression_metrics.csv')\n",
    "# c_metrics = pd.read_csv('./data/Classification_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 5))\n",
    "# for i in r_metrics['Model'].unique(): \n",
    "#     plt.title('Correlation Coefficient');\n",
    "#     draw_r_metrics = r_metrics.loc[r_metrics['Model']==i]\n",
    "#     plt.plot(draw_r_metrics.loc[:,'NumSamples'], draw_r_metrics.loc[:,'R'], '-o', label=i)\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.xlabel('Number of samples');\n",
    "# plt.xticks(np.arange(0, draw_r_metrics['NumSamples'].iloc[-1], step=5000), rotation=50);\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 10))\n",
    "# for i in r_metrics['Model'].unique(): \n",
    "#     plt.title('Mean Squared Error');\n",
    "#     draw_r_metrics = r_metrics.loc[r_metrics['Model']==i]\n",
    "#     plt.plot(draw_r_metrics.loc[:,'NumSamples'], draw_r_metrics.loc[:,'MSE'], '-o', label=i)\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.xlabel('Number of samples');\n",
    "# plt.xticks(np.arange(0, draw_r_metrics['NumSamples'].iloc[-1], step=5000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 5))\n",
    "# for i in r_metrics['Model'].unique(): \n",
    "#     plt.title('Standard Deviation');\n",
    "#     draw_r_metrics = r_metrics.loc[r_metrics['Model']==i]\n",
    "#     plt.plot(draw_r_metrics.loc[:,'NumSamples'], draw_r_metrics.loc[:,'STD'], '-o', label=i)\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.xlabel('Number of samples');\n",
    "# plt.xticks(np.arange(0, draw_r_metrics['NumSamples'].iloc[-1], step=5000));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
